<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Getting Started With TensorFlow</title>
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Wu, Shanliang" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Getting Started With TensorFlow</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">Tensors</a></li>
<li><a href="#sec-2">TensorFlow Core tutorial</a>
<ul>
<li><a href="#sec-2-1">Importing TensorFlow</a></li>
<li><a href="#sec-2-2">The Computational Graph</a></li>
</ul>
</li>
</ul>
</div>
</div>
<p>
This guide gets you started programming in TensorFlow. Before using this guide, install TensorFlow. To get the most out of this guide, you should know the following:
</p>
<ul class="org-ul">
<li>How to program in Python
</li>
<li>At least a little bit about arrays
</li>
<li>Ideally, something about machine learning. However, if you know little or nothing about machine learning, then this is still the first guide you should read
</li>
</ul>

<p>
TensorFlow provides multiple APIs. The lowest level API&#x2013; <b>TensorFlow Core</b> &#x2013; provides you with complete programming control. We recommend TensorFlow Core for machine learning researchers and others who require fine levels of control over their models. The higher level APIs are built on top of TensorFlow Core. These higher level APIs are typically easier to learn and use than TensorFlow Core. In addition, the higher level APIs make repetitive tasks easier and more consistent between different users. A high-level API like tf.estimator helps you manage data sets, estimators, training and inference
</p>

<p>
This guide begins with a tutorial on TensorFlow Core. Later, we demonstrate how to implement the same model in tf.estimator. Knowing TensorFlow Core principles will give you a great mental model of how things are working internally when you use the more compact higher level API
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">Tensors</h2>
<div class="outline-text-2" id="text-1">
<p>
The central unit of data in TensorFlow is the <b>tensor</b> . A tensor consists of a set of primitive values shaped into an array of any number of dimensions. A tensor's <b>rank</b> is its number of dimensions. Here are some examples of tensors: 
</p>

<div class="org-src-container">

<pre class="src src-python">3 <span style="color: #ff4500;"># </span><span style="color: #ff4500;">a rank 0 tensor; a scalar with shape []</span>
[1., 2., 3.] <span style="color: #ff4500;"># </span><span style="color: #ff4500;">a rank 1 tensor; a vector with shape [3]</span>
[[1., 2., 3.], [4., 5., 6.]] <span style="color: #ff4500;"># </span><span style="color: #ff4500;">a rank 2 tensor; a matrix with shape [2, 3]</span>
[[[1., 2., 3.]], [[7., 8., 9.]]] <span style="color: #ff4500;"># </span><span style="color: #ff4500;">a rank 3 tensor with shape [2, 1, 3]</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">TensorFlow Core tutorial</h2>
<div class="outline-text-2" id="text-2">
</div><div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1">Importing TensorFlow</h3>
<div class="outline-text-3" id="text-2-1">
<p>
The canonical import statement for TensorFlow programs is as follows:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #00ffff;">import</span> tensorflow <span style="color: #00ffff;">as</span> tf
</pre>
</div>

<p>
This gives Python access to all of TensorFlow's classes, methods, and symbols. Most of the documentation assumes you have already done this
</p>
</div>
</div>

<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2">The Computational Graph</h3>
<div class="outline-text-3" id="text-2-2">
<p>
You might think of TensorFlow Core programs as consisting of two discrete sections:
</p>
<ol class="org-ol">
<li>Building the computational graph
</li>
<li>Running the computational graph
</li>
</ol>

<p>
A <b>computational graph</b> is a series of TensorFlow operations arranged into a graph of nodes. Let's build a simple computational graph. Each node takes zero or more tensors as inputs and produces a tensor as an output. One type of node is a constant. Like all TensorFlow constants, it takes no inputs, and it outputs a value it stores internally. We can create two floating point Tensors node1 and node2 as follows:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #eedd82;">node1</span> = tf.constant(3.0, dtype=tf.float32)
<span style="color: #eedd82;">node2</span> = tf.constant(4.0) <span style="color: #ff4500;"># </span><span style="color: #ff4500;">also tf.float32 implicitly</span>
<span style="color: #00ffff;">print</span>(node1, node2)
</pre>
</div>

<p>
The final print statement produces
</p>
<pre class="example">
Tensor("Const:0", shape=(), dtype=float32) Tensor("Const_1:0", shape=(), dtype=float32)
</pre>

<p>
Notice that printing the nodes does not output the values 3.0 and 4.0 as you might expect. Instead, they are nodes that, when evaluated, would produce 3.0 and 4.0, respectively. To actually evaluate the nodes, we must run the computational graph within a <b>session</b> . A session encapsulates the control and state of the TensorFlow runtime
</p>

<p>
The following code creates a <i>Session</i> object and then invokes its <i>run</i> method to run enough of the computational graph to evaluate <i>node1</i> and <i>node2</i> . By running the computational graph in a session as follows:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #eedd82;">sess</span> = tf.Session()
<span style="color: #00ffff;">print</span>(sess.run([node1, node2]))
</pre>
</div>

<p>
we see the expected values of 3.0 and 4.0:
</p>

<pre class="example">
[3.0, 4.0]
</pre>

<p>
We can build more complicated computations by combining Tensor nodes with operations (Operations are also nodes). For example, we can add our two constant nodes and produce a new graph as follows:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #00ffff;">from</span> __future__ <span style="color: #00ffff;">import</span> print_function
<span style="color: #eedd82;">node3</span> = tf.add(node1, node2)
<span style="color: #00ffff;">print</span>(<span style="color: #ffa07a;">"node3:"</span>, node3)
<span style="color: #00ffff;">print</span>(<span style="color: #ffa07a;">"sess.run(node3):"</span>, sess.run(node3))
</pre>
</div>

<p>
The last two print statements produce
</p>

<pre class="example">
node3: Tensor("Add:0", shape=(), dtype=float32)
sess.run(node3): 7.0
</pre>

<p>
TensorFlow provides a utility called TensorBoard that can display a picture of the computational graph. Here is a screenshot showing how TensorBoard visualizes the graph:
</p>


<div class="figure">
<p><img src="pic/getting_started_add.png" alt="getting_started_add.png" width="30%" />
</p>
</div>

<p>
As it stands, this graph is not especially interesting because it always produces a constant result. A graph can be parameterized to accept external inputs, known as <b>placeholders</b> . A <b>placeholder</b> is a promise to provide a value later
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #eedd82;">a</span> = tf.placeholder(tf.float32)
<span style="color: #eedd82;">b</span> = tf.placeholder(tf.float32)
<span style="color: #eedd82;">adder_node</span> = a + b  <span style="color: #ff4500;"># </span><span style="color: #ff4500;">+ provides a shortcut for tf.add(a, b)</span>
</pre>
</div>

<p>
The preceding three lines are a bit like a function or a lambda in which we define two input parameters (a and b) and then an operation on them. We can evaluate this graph with multiple inputs by using the feed<sub>dict</sub> argument to the run method to feed concrete values to the placeholders:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #00ffff;">print</span>(sess.run(adder_node, {a: 3, b: 4.5}))
<span style="color: #00ffff;">print</span>(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))
</pre>
</div>

<p>
resulting in the output
</p>

<pre class="example">
7.5
[ 3.  7.]
</pre>

<p>
In TensorBoard, the graph looks like this:
</p>


<div class="figure">
<p><img src="pic/getting_started_adder.png" alt="getting_started_adder.png" width="30%" />
</p>
</div>

<p>
We can make the computational graph more complex by adding another operation. For example,
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #eedd82;">add_and_triple</span> = adder_node * 3.
<span style="color: #00ffff;">print</span>(sess.run(add_and_triple, {a: 3, b: 4.5}))
</pre>
</div>

<p>
produces the output
</p>
<pre class="example">
22.5
</pre>

<p>
The preceding computational graph would look as follows in TensorBoard:
</p>


<div class="figure">
<p><img src="pic/getting_started_triple.png" alt="getting_started_triple.png" width="30%" />
</p>
</div>

<p>
In machine learning we will typically want a model that can take arbitrary inputs, such as the one above. To make the model trainable, we need to be able to modify the graph to get new outputs with the same input. Variables allow us to add trainable parameters to a graph. They are constructed with a type and initial value:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #eedd82;">W</span> = tf.Variable([.3], dtype=tf.float32)
<span style="color: #eedd82;">b</span> = tf.Variable([-.3], dtype=tf.float32)
<span style="color: #eedd82;">x</span> = tf.placeholder(tf.float32)
<span style="color: #eedd82;">linear_model</span> = W*x + b
</pre>
</div>

<p>
Constants are initialized when you call <b>tf.constant</b> , and their value can never change. By contrast, variables are not initialized when you call <b>tf.Variable</b> . To initialize all the variables in a TensorFlow program, you must explicitly call a special operation as follows:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #eedd82;">init</span> = tf.global_variables_initializer()
sess.run(init)
</pre>
</div>

<p>
It is important to realize <b>init</b> is a handle to the TensorFlow sub-graph that initializes all the global variables. Until we call <b>sess.run</b> , the variables are uninitialized
</p>

<p>
Since <b>x</b> is a placeholder, we can evaluate linear<sub>model</sub> for several values of x simultaneously as follows:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #00ffff;">print</span>(sess.run(linear_model, {x: [1, 2, 3, 4]}))
</pre>
</div>

<p>
to produce the output
</p>

<pre class="example">
[ 0.          0.30000001  0.60000002  0.90000004]
</pre>

<p>
We've created a model, but we don't know how good it is yet. To evaluate the model on training data, we need a y placeholder to provide the desired values, and we need to write a loss function.
</p>

<p>
A loss function measures how far apart the current model is from the provided data. We'll use a standard loss model for linear regression, which sums the squares of the deltas between the current model and the provided data.  <b>linear<sub>model</sub> - y</b>  creates a vector where each element is the corresponding example's error delta. We call <b>tf.square</b> to square that error. Then, we sum all the squared errors to create a single scalar that abstracts the error of all examples using <b>tf.reduce<sub>sum</sub></b> :
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #eedd82;">y</span> = tf.placeholder(tf.float32)
<span style="color: #eedd82;">squared_deltas</span> = tf.square(linear_model - y)
<span style="color: #eedd82;">loss</span> = tf.reduce_sum(squared_deltas)
<span style="color: #00ffff;">print</span>(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))
</pre>
</div>

<p>
producing the loss value
</p>

<pre class="example">
23.66
</pre>

<p>
We could improve this manually by reassigning the values of  <b>W</b> and <b>b</b> to the perfect values of -1 and 1. A variable is initialized to the value provided to tf.Variable but can be changed using operations like <b>tf.assign</b> . For example, W=-1 and b=1 are the optimal parameters for our model. We can change <b>W</b> and <b>b</b> accordingly:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #eedd82;">fixW</span> = tf.assign(W, [-1.])
<span style="color: #eedd82;">fixb</span> = tf.assign(b, [1.])
sess.run([fixW, fixb])
<span style="color: #00ffff;">print</span>(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))
</pre>
</div>

<p>
The final print shows the loss now is zero 
</p>

<pre class="example">
0.0
</pre>

<p>
We guessed the "perfect" values of <b>W</b> and <b>b</b> , but the whole point of machine learning is to find the correct model parameters automatically. We will show how to accomplish this in the next section </p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Wu, Shanliang</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 25.1.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
