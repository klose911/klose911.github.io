#+TITLE: Transformer 
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/main.css" />
#+OPTIONS: num:nil timestamp:nil  ^:nil

Transformer是一类 _神经网络_ 架构

#+begin_example
  Transformer 现在越来越受欢迎了，最近被OpenAI用于训练他们的语言模型

  同时也被DeepMind的AlphaStar 采用，用于他们的程序击败那些顶级星际玩家
#+end_example

Transformer是为了解决 _序列传导_ 问题或神经网络 _机器翻译_ 而设计的，意味着任何需要将 _输入序列_ *转换* 为 _输出序列_ 的任务都可以用，包括语音识别和文本到语音转换等 

#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b6ff201a4.gif]]

对于需要进行 _序列传导_ 的模型，有必要有某种 *记忆*

#+begin_example
  例如，将以下句子翻译到另一种语言(法语):

  “The Transformers” are a Japanese [[hardcore punk]] band. The band was formed in 1968, during the height of Japanese music history”

  本例中，第二句话中的“the band”一词指代第一句中引入的“The Transformers”

  当读到第二句中的"the band"，你知道它指的是“The Transformers” band

  这对翻译很重要。事实上，后一句话中的某个词指代前几句话中出现的某个词，像这样的例子很多
#+end_example

翻译这样的句子，模型需要找出之间的依赖和关联。 *循环神经网络*  _RNNs_ 和 *卷积神经网络* _CNNs_ 由于其特性已被使用来解决这个问题。 首先来回顾一下这两种架构及其缺点
* 循环神经网络
循环神经网络内部有 _循环_ ，允许 _信息_ *保存* 其中 

#+ATTR_HTML: image :width 50% 
[[file:pic/5c90b70c90e90.png]]

如上图所示，可以看到神经网络的一部分 $A$，处理 *输入* $x_t$，然后 *输出* $h_t$ ， A处循环 使得 *信息可从前一步传递至后一步*

#+begin_example
  换一种方式思考这些循环：循环神经网络可认为是同一网络A的多重备份，每个网络将信息传递给其后续网络
#+end_example
看一下如果将循环展开会如何：
#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b713778c5.png]]

图中 *链式* 本质清楚地表明循环神经网络与序列和列表相关
#+begin_example
  如果以这种方式翻译一段文本，需要将文本中的每个单词设置为其输入

  循环神经网络将序列中前面的词语的信息传入后一个神经网络，这样便可以利用和处理这些信息
#+end_example

下图展示了 _sequence to sequence_ 模型通常是如何用循环神经网络工作的。每个单词被单独处理，然后将 _编码阶段的隐状态_ *传入* _解码阶段_ 以 *生成* _结果句子_ ，然后这样就产生了输出 
#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b727ad045.gif]]

** 长期依赖的问题
考虑一下这类模型，即使用之前看到的单词预测下一个单词

#+begin_example
  如果需要预测这句话“the clouds in the ___”的下一个单词，不需要额外的语境信息，很显然下个单词是“sky”

  这个例子里，相关信息和需预测单词的距离很近
#+end_example

循环神经网络可以学习前面的信息，并找出句中下一个单词：
#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b731e6876.png]]

但有些情况需要更多语境信息

#+begin_example
  例如试图预测这句话的最后一个单词: “I grew up in France… I speak fluent ___”

  最靠近这个单词的信息建议这很有可能是一种语言，但当想确定具体是哪种语言时，需要语境信息France

  而这出现在较前面的文本中
#+end_example
#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b73ccd5e8.png]]

当相关信息和词语之间距离变得很大时，RNN变得非常低效。那是因为，需要翻译的信息经过运算中的每一步，传递链越长，信息就越可能在链中丢失

#+begin_example
  理论上RNN可以学习这些长期依赖关系，不过实践表现不佳，学不到这些信息

  因而出现了LSTM，一种特殊的RNN，试图解决这类问题
#+end_example

** Long-Short Term Memory (LSTM)
#+begin_example
  我们平时安排日程时，通常会为不同的约会确定不同的优先级

  如果有什么重要行程安排，我们通常会取消一些不那么重要的会议，去参加那些重要的

  RNN不会那么做。无论什么时候都会不断往后面加信息，它通过应用函数转换全部现有信息

  在过程中所有信息都被修改了，它不去考虑哪些重要，哪些不重要
#+end_example
_LSTMs_ 在此基础上利用 _乘法_ 和 _加法_ 做了一些小改进。在LSTMs里， _信息流_ 经一种机制称为 *细胞状态* 。LSTM便可以选择性的记忆或遗忘那些重要或不重要的事情了。LSTM内部看起来像是这样:
#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b74d67b86.png]]

每个细胞的输入为 $x_t$ (在句子到句子翻译这类应用中 $x_t$ 是一个单词), 上一轮细胞状态以及上一轮的输出。模型基于这些输入计算改变其中信息，然后产生新的细胞状态和输出

#+begin_example
  这里不会详细讲每个细胞的实现机制，如果想了解这些细胞的运作机制，推荐看一下Christopher的博客:

  Understanding LSTM Networks -- colah's blog https://colah.github.io/posts/2015-08-Understanding-LSTMs/
#+end_example

这些循环使得循环神经网络看起来有点神秘。 但如果再细想一下，事实上采用细胞状态后，在翻译过程中，句子中对翻译单词重要的信息会被一轮一轮传递下去

*** LSTM的问题
#+begin_example
  总体来说问题LSTM的问题与RNN一样

  例如当句子过长LSTM也不能很好的工作

  原因在于保持离当前单词较远的上下文的概率以距离的指数衰减，那意味着当出现长句，模型通常会忘记序列中较远的内容

  RNN与LSTM模型的另一个问题，由于不得不逐个单词处理，因此难以并行化处理句子。不仅如此，也没有长短范围依赖的模型
#+end_example
总之，LSTM和RNN模型有三个问题:
+ 顺序计算，不能有效并行化
+ 没有显示的建模长短范围依赖
+ 单词之间的距离是线性的


** Attention
#+begin_example
  为了解决其中部分问题，研究者建立了一项能对特定单词产生注意力的技能

  当翻译一个句子，我会特别注意我当前正在翻译的单词

  当我录制录音时，我会仔细聆听我正在写下的部分

  如果你让我描述我所在的房间，当我这样做的时候，我会瞥一眼描述的物体

  神经网络用attention可以做到同样的效果，专注于给出信息的那部分

  例如，RNN可以会注意另一RNN的输出。在每个时点它聚焦于其他RNN不同的位置
#+end_example


*注意力* _attention_ 是一种用于神经网络的技术。 对于RNN模型，与其只编码整个句子的隐状态，可以把 _每个单词的隐状态_ 一起传给 _解码器阶段_ 。在RNN的每个步骤使用隐藏状态进行解码。详见下面动图

#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b761dc460.gif]]

#+begin_example
其背后的想法是句子每个单词都有相关信息。为了精确解码，需要用注意力机制考虑输入的每个单词
#+end_example
对于要放入序列传导RNN模型的注意力，分成 _编码_ 和 _解码_ 两步。一步以绿色（编码）表示，另一步以紫色（解码）表示。

绿色步骤负责由 _输入_ *建立* _隐状态_ 。把句子中每个单词产生的 *所有* _隐状态_ *传入* _解码_ 阶段，而不是和过去一样，仅传递一个隐状态给解码器。每个隐状态都会在解码阶段被使用，去找出网络应该注意的地方。

#+begin_example
比如，当翻译这句 “Je suis étudiant”法语句子到英语时，需要在翻译时解码步骤去查不同的单词
#+end_example

#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b769428f4.gif]]

#+begin_example
  或再比如，当将“L’accord sur la zone économique européenne a été signé en août 1992.” 法语翻译成英语
#+end_example

下图展示了需要对每个输入赋予多少注意力：

#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b7a4292b2.png]] 

#+begin_example
  不过前面讨论的一些问题，用带attention的RNN仍然无法解决

  比如，不可能并行处理输入的单词，这对较大的文本语料，增加了翻译文本的用时
#+end_example
* 卷积神经网络
卷积神经网络可以帮助解决这些问题，可以做到：
+ 并行化 (按层)
+ 利用局部依赖
+ 位置间的距离是对数级的

一些流行的序列传导网络, 例如 Wavenet 和 Bytenet 就采用卷积神经网络
#+ATTR_HTML: image :width 80% 
[[file:pic/5c904f120148e.gif]] 

卷积神经网络可并行处理是因为，输入的每个单词可被同时处理并不必依赖于前一个单词翻译的结果。不仅如此，输出单词与任何CNN输入的单词的“距离”是 $\log{N}$  数量级：即输入单词到输出单词连线形成的树的高度 (如上面动图所示)。 这比RNN输出到其输入的距离要好很多，因为其距离是 $N$ 数量级

#+begin_example
  问题在于卷积神经网络在翻译句子过程中不一定有助于解决依赖问题

  这就是transformers被创造出来的原因，它结合了CNN和attention机制
#+end_example

* Transformers 
现在来看一下Transformer是如何工作的。 *Transformer* 是一类用attention来 *提速* 的模型，具体来说使用的是 _self-attention_ 

#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b7af031d3.png]] 

从内部来看Transformer与之前模型架构相似，只是Transformer由 _6_ 个 *编码器* 和 _6_ 个 *解码器* 组成
#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b7bac6c85.png]] 

编码器非常相似，所有编码器都具有相同的架构。解码器也有相同的属性诸如互相之间非常相似。编码器有两层:  _self-attention层_ 和 _前馈神经网络层_

#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b7c680e20.png]]

编码器的输入先进入 _self-attention层_ ，有助于编码器在编码句中特定单词时可参考输入句子中其他单词。解码器也包含这两层，不过在两层中间增加了 _attention层_ ，以帮助解码器 *聚焦* 到 _输入句子的相关部分_ 
#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b7cedd28a.png]]

** Self-Attention
#+begin_example
  注: 这部分转自Jay Allamar的博文 https://jalammar.github.io/illustrated-transformer/
#+end_example

先来看一下模型中各种不同的 _向量_ /张量，它们在已训练模型组件中如何流转，从而把输入转化成输出的。 由于这是一个NLP应用实例，我们先用 *词嵌入* _embedding_ 算法把每个输入的词语转换为 _词向量_ 
#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b7d790a9a.png]] 

每个单词被转换为一个 _长度512_ 的 *向量* 。图中用这些简单的 _方块_ 表示这些向量：
+ 仅在 *最底层* 的 编码器处进行词嵌入转换。对于所有编码器，它们都接收大小为512的向量列表
+ 最底层的编码器接收的是词嵌入，但其他编码器接收的输入是其下一层的直接输出
  + 当输入序列中的单词做词嵌入转换后，数据就按 *顺序* 流经各层编码器的2层结构

#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b7e1abad0.png]] 

此处开始看到Transformer的一个重要特性， _每个位置上的单词_ 在 _编码器_ 中流经 *自己的* _路径_
+ 在self-attention层处理这些路径的依赖关系
+ 前馈神经网络不处理这些依赖关系，这样当数据流经前馈神经网络时，不同的路径可被 *并行* 执行

#+begin_example
接下来，将切换到一句短句实例，看一下在编码器的子层里会发生什么
#+end_example

*** 计算 self-attention  
首先来看一下如何用向量计算self-attention，然后再看一下利用矩阵运算的实现方式：

#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b7eb74c91.png]] 

self-attention计算的第一步是通过编码器的 _输入向量_ (本例中是每个单词的词嵌入向量) 建立 _Query_ ,  _Key_ 和 _Value_ 三个向量，通过 _输入的词嵌入向量_ *乘以* _之前训练完成的三个矩阵_ 得到。这些 _新向量的长度_ *小于* _词嵌入向量的长度_ 。这里取 $64$，而词嵌入向量及编码器的输入输出长度为 $512$

#+begin_example
这是一个架构性选择，向量长度不需要变得更小，使得多头注意力(multiheaded attention)计算基本稳定
#+end_example

#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b7f6c549d.png]] 

将 _词向量_ $x_1$ *乘以* _权重矩阵_ $W^Q$ 得到 $q_1$，即与这个单词关联的 *query* 向量

#+begin_example
  这样，最终分别得到输入句子里每个单词的“query”,“key”和“value”投射

  那“query”, “key”和“value”向量是什么? 它们是一种抽象，在计算和考虑注意力时会被用到
#+end_example

计算self-attention的第二步是计算一项 *得分* _score_ 。在特定的位置编码一个单词时，该得分决定了在 _输入句子的其他部分_ *需要* 放多少 _焦点_ 。因此需要计算句中 _每个单词_ 针对 _这个词_ 的得分：
+ 得分等于 _当前词的query向量_ 与 _需评分词语的key向量_ 的 *点积*

#+begin_example
以计算句中第一个单词 "Thinking" 的self-attention为例：

如果需要计算#1位置处单词的self-attention，第一个得分是q1与k1的点积，第二个得分就是q1和k2的点积 
#+end_example

#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b80044a64.png]] 

第三步是将所有 _得分_ *除以* $8$ 
#+begin_example
论文中取的是 ”向量维数开根号“ 64，这样会得到更稳定的梯度。当然也可以用其他值，不过这是默认值)
#+end_example

第四步将结果放入一个 _softmax_ 操作来 *正则化* 这些得分，使它们都 *大于0且加和为1*

#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b80e3403b.png]] 

这个经过softmax的score决定了 _该单词_ 在 _这个位置_ *表达* 了 _多少_

#+begin_example
  很显然当前位置所在的单词会得到最高的softmax得分，不过有时候有助于算法注意到其他与当前单词相关的单词
#+end_example

第五步，将 _每个value向量_ *乘以*  _softmax得分_ (准备对它们求和)

#+begin_example
这里的意图是保持需要聚焦的单词的value，并且去除不相关的单词, 这时候score 会是一个很小的数字 比如0.001
#+end_example

第六步 *求和加权* 后的 _value向量_ 。这就产生了对于 _第一个单词_ 在 _self-attention层_ 上 _此位置的输出_ 
#+ATTR_HTML: image :width 80% 
[[file:pic/5c90b818e1a61.png]] 

_self-attention的结果向量_ 就可以拿来作为 _前馈神经网络_ 的 *输入* 

#+begin_example
不过实际实现中，考虑到性能该计算由矩阵形式运算完成
#+end_example

*** 矩阵计算
第一步是计算查询 _Query_ , 键 _Key_ 和值 _Value_  *矩阵* 。通过将 _嵌入向量_ 打包到一个矩阵 $X$ 中，然后将其与训练的权重矩阵 $W^Q$ , $W^K$ , $W^V$ *相乘* 来实现这一点：

#+ATTR_HTML: image :width 80% 
[[file:pic/self-attention-matrix-calculation.png]]

#+begin_example
  X 矩阵中的每一行对应输入句子中的一个单词

  再次看到嵌入向量的大小（512，或图中的4个框）和 q/k/v 向量的大小（64，或图中的3个框）之间的差异
#+end_example

最后，由于处理的是矩阵，可以将步骤二到步骤六浓缩成一个公式来计算自注意力层的输出：

#+ATTR_HTML: image :width 80% 
[[file:pic/self-attention-matrix-calculation-2.png]]

** Multihead attention 
这篇论文通过添加一种称为 *多头* 注意力的机制进一步优化了自注意力层。这在两个方面提高了注意力层的性能：
1. 扩展模型关注不同位置的能力：
   #+begin_example
     是的，在上面的例子中， z_1 包含了其他编码的一部分，但它可能会被实际单词本身所主导

     如果正在翻译一句像“The animal didn’t cross the street because it was too tired”的句子，知道“it”指的是哪个单词会很有用
   #+end_example
2. 为注意力层提供多个 *表示子空间* ：通过多头注意力，不仅拥有一组查询/键/值权重矩阵，而是有多组。每组权重矩阵都是随机初始化的。然后，在训练之后，每组权重矩阵用于将输入的嵌入（或来自较低编码器/解码器的向量）投影到不同的表示子空间中
   #+begin_example
     Transformer 使用八个注意力头，所以我们最终为每个编码器/解码器得到八组
   #+end_example

#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_attention_heads_qkv.png]] 

#+begin_example
  在多头注意力机制中，我们为每个头分别保持独立的 Q/K/V 权重矩阵，从而产生不同的 Q/K/V 矩阵

  与之前一样，我们将 X 矩阵乘以 W^Q/W^K/W^V 权重矩阵以生成 Q/K/V 矩
#+end_example

如果按照上面概述的自注意力计算方式，使用不同的权重矩阵重复进行八次，最终得到八个不同的 $Z$ 矩阵: 
#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_attention_heads_z.png]] 

#+begin_example
  这带来了一些挑战。前馈层并不期望得到八个矩阵：它期望得到一个单独的矩阵（每个单词对应一个向量）

  因此，需要一种方法将这八个矩阵压缩成一个单独的矩阵。那么如何做到这一点？
#+end_example
可以将这些矩阵 *连接* 起来，然后再 *乘以* 额外的 权重矩阵 $W^O$

#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_attention_heads_weight_matrix_o.png]] 

这基本上就是多头自注意力的全部内容了。这里有相当多的矩阵。尝试将它们都放在一个可视化图中，这样就可以一目了然地看到它们：

#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_multi-headed_self-attention-recap.png]] 

现在重新审视之前的例子，看看在例句中的单词“it”时，不同的注意力头部在关注哪些内容：

#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_self-attention_visualization_2.png]] 

#+begin_example
  在编码单词“it”时，一个注意力头部主要关注“the animal”，而另一个注意力头部则关注“tired”

  在某种意义上，模型对单词“it”的表示中融入了“animal”和“tired”的部分表示
#+end_example

如果把所有的注意力头都放入图片，那么会更难以解释：

#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_self-attention_visualization_3.png]] 

** Positional Encoding
#+begin_example
在目前描述的模型中，缺少了一种处理输入序列中单词顺序的方法
#+end_example

为了解决这个问题，Transformer 为每个 _输入嵌入_ *添加* 了一个 _向量_ 。这些向量遵循特定的模式，模型可以学习这种模式，从而帮助它确定 _每个单词的位置_ ，或者序列中 _不同单词之间的距离_

#+begin_example
直观上来说，将这些值添加到嵌入中后，当它们被投射到 Q/K/V 向量中并在点积注意力中使用时，嵌入向量之间的距离会变得有意义
#+end_example

#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_positional_encoding_vectors.png]] 

如果假设嵌入的维度为 4，实际的位置编码将如下所示：

#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_positional_encoding_example.png]]

#+begin_example
实际的模型现在看起来如何呢？ 
#+end_example

在下图中，每一行对应一个 _向量的位置编码_ 。因此，第一行将是我们添加到输入序列中第一个单词嵌入的向量。每一行包含 512 个值：每个值的范围在 1 和 -1 之间。使用颜色编码使其模式可见

#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_positional_encoding_large_example.png]]

#+begin_example
  这是一个实际的例子，展示了 20 个单词（行）的位置编码，嵌入大小为 512（列）。可以看到它在中间似乎被分成了两半

  这是因为左半部分的值是由一个函数（使用正弦函数）生成的，而右半部分是由另一个函数（使用余弦函数）生成的。然后将它们连接起来，形成每个位置编码向量
#+end_example

在论文的第 3.5 节中描述了位置编码的公式。可以在 _get_timing_signal_1d()_ 方法中看到生成位置编码的代码

#+begin_example
  这并不是唯一可能的方法进行位置编码。然而，它具有能够扩展到未见过长度的序列的优势

  例如，如果训练模型被要求翻译一个比 训练集 中任何句子都长的句子
#+end_example

2020年7月更新：下面显示的位置编码来自 Tensor2Tensor 对 Transformer 的实现。论文中展示的方法略有不同，它并不是直接连接，而是交织这两个信号。下图显示了其外观：
#+ATTR_HTML: image :width 80% 
[[file:pic/attention-is-all-you-need-positional-encoding.png]]

** Residuals
在继续之前，需要提到编码器架构中的一个细节，即每个编码器中的每个子层（自注意力机制、前馈神经网络）都有一个 *残差连接* ，并且在其后进行 *层归一化* 步骤

#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_resideual_layer_norm.png]]

如果要将与自注意力机制相关的向量和层归一化操作可视化，它看起来会是这样的：
#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_resideual_layer_norm_2.png]] 

这同样适用于解码器的子层。想象一个堆叠了两个编码器和解码器的Transformer模型，它看起来会是这样的：
#+ATTR_HTML: image :width 80% 
[[file:pic/transformer_resideual_layer_norm_3.png]] 

** 解码器
#+ATTR_HTML: image :width 80% 
[[file:pic/]] 
