#+TITLE: 虚拟内存
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/main.css" />
#+HTML_LINK_UP: ./system_call.html
#+HTML_LINK_HOME: ./rpios.html
#+OPTIONS: num:nil timestamp:nil ^:nil

现在，RPi OS可以运行和调度用户进程，但它们之间的隔离并不完整：所有进程和内核本身共享同一块内存。这使得任何进程都可以轻易地访问其他进程甚至内核数据

#+begin_example
  即使假设所有的进程都不是恶意的，仍然存在另一个缺点：在分配内存之前，每个进程都需要知道哪些内存区域已被占用

  这使得进程的内存分配变得更加复杂
#+end_example
* 地址转换
接下来将通过引入 _虚拟内存_ 来解决上述所有问题。虚拟内存为每个进程提供了一个抽象，使其认为它占用了所有可用的内存。每当一个进程需要访问某个内存位置时，它使用虚拟地址，该地址会被转换为物理地址。转换的过程完全对进程透明，由一个特殊设备进行：*MMU*（ _内存映射单元_ ）。MMU使用 _转换表_ 来将虚拟地址转换为物理地址。转换的过程如下图所示：

#+begin_example
			     Virtual address                                                                 Physical Memory
  +-----------------------------------------------------------------------+                                +------------------+
  |         | PGD Index | PUD Index | PMD Index | PTE Index | Page offset |                                |                  |
  +-----------------------------------------------------------------------+                                |                  |
  63        47     |    38      |   29     |    20    |     11      |     0                                |     Page N       |
		   |            |          |          |             +--------------------+           +---->+------------------+
		   |            |          |          +---------------------+            |           |     |                  |
	    +------+            |          |                                |            |           |     |                  |
	    |                   |          +----------+                     |            |           |     |------------------|
  +------+  |        PGD        |                     |                     |            +---------------->| Physical address |
  | ttbr |---->+-------------+  |           PUD       |                     |                        |     |------------------|
  +------+  |  |             |  | +->+-------------+  |          PMD        |                        |     |                  |
	    |  +-------------+  | |  |             |  | +->+-------------+  |          PTE           |     +------------------+
	    +->| PUD address |----+  +-------------+  | |  |             |  | +->+--------------+    |     |                  |
	       +-------------+  +--->| PMD address |----+  +-------------+  | |  |              |    |     |                  |
	       |             |       +-------------+  +--->| PTE address |----+  +-------------_+    |     |                  |
	       +-------------+       |             |       +-------------+  +--->| Page address |----+     |                  |
				     +-------------+       |             |       +--------------+          |                  |
							   +-------------+       |              |          |                  |
										 +--------------+          +------------------+
#+end_example

以下事实对于理解这个图表和内存转换过程非常重要：
+ 进程的内存总是以 _页面_ 为单位分配的。页面是一个连续的内存区域，大小为 _4KB_
  #+begin_example
    ARM处理器支持更大的页面，但4KB是最常见的情况，这里将限制讨论在这个页面大小上
  #+end_example
+ _页表_ 具有 *分层* 结构。在任何一个表中的项目包含了层次结构中下一个表的地址
+ 表层次结构中有4个级别：
  + *PGD* :  _页全局目录_ (Page Global Directory)
  + *PUD* :  _页上级目录_ (Page Upper Directory)
  + *PMD* :  _页中间目录_ (Page Middle Directory)
  + *PTE* : _页表项_ (Page Table Entry) PTE是层次结构中的最后一个表，它指向 *物理内存* 中的 _实际页面_ 
+ 内存转换过程从 *定位*  _PGD_ （页全局目录）表的地址开始。该表的地址存储在 *ttbr0_el1寄存器* 中
+ *每个进程都有自己的所有页表的副本* ，包括 _PGD_ ，因此每个进程都必须保持其PGD地址。在 *上下文切换* 期间，将 _下一个进程_ 的 _PGD地址_ *加载* 到 _ttbr0_el1寄存器_ 中
+ 然后， _MMU_ 使用PGD指针和虚拟地址计算相应的物理地址。所有虚拟地址仅使用64位中的 _48位_ 。在进行转换时，MMU将地址分为4个部分：
  + *位[39-47]* : 包含 _PGD表中的索引_
    #+begin_example
      MMU使用此索引查找PUD的位置
    #+end_example
  + *位[30-38]* : 包含 _PUD表中的索引_
    #+begin_example
      MMU使用此索引查找PMD的位置
    #+end_example
  + *位[21-29]* : 包含 _PMD表中的索引_
    #+begin_example
      MMU使用此索引查找PTE的位置
    #+end_example
  + *位[12-20]* : 包含 _PTE表中的索引_
    #+begin_example
      MMU使用此索引在物理内存中找到一个页面
    #+end_example
  + *位[0-11]* : 包含 _物理页面中的偏移量_
    #+begin_example
      MMU使用此偏移量确定在之前找到的页面中与原始虚拟地址对应的确切位置 
    #+end_example

  #+begin_example
    现在，让我们进行一个小练习，计算页表的大小

    从上面的图表中，知道页表中的索引占据9位（对于所有的页表级别都是如此）: 这意味着每个页表包含2^9 = 512个条目

    每个页表中的条目是层次结构中下一个页表或者PTE情况下的物理页面的地址。由于使用的是64位处理器，每个地址必须是64位或8字节大小

    将所有这些放在一起，我们可以计算出一个页表的大小必须是512 * 8 = 4096字节或4 KB。这正是一个页面的大小！

    这可能会让你对为什么MMU设计者选择这样的数字产生直觉
  #+end_example
* 区段映射
有时候需要映射连续的大内存区域。在这种情况下，可以直接映射2 MB大小的块，称为 _区段_ 。这样可以省去一级的地址转换。在这种情况下，转换图如下所示：

#+begin_example
			     Virtual address                                               Physical Memory
  +-----------------------------------------------------------------------+              +------------------+
  |         | PGD Index | PUD Index | PMD Index |      Section offset     |              |                  |
  +-----------------------------------------------------------------------+              |                  |
  63        47     |    38      |   29     |    20            |           0              |    Section N     |
		   |            |          |                  |                    +---->+------------------+
		   |            |          |                  |                    |     |                  |
	    +------+            |          |                  |                    |     |                  |
	    |                   |          +----------+       |                    |     |------------------|
  +------+  |        PGD        |                     |       +------------------------->| Physical address |
  | ttbr |---->+-------------+  |           PUD       |                            |     |------------------|
  +------+  |  |             |  | +->+-------------+  |            PMD             |     |                  |
	    |  +-------------+  | |  |             |  | +->+-----------------+     |     +------------------+
	    +->| PUD address |----+  +-------------+  | |  |                 |     |     |                  |
	       +-------------+  +--->| PMD address |----+  +-----------------+     |     |                  |
	       |             |       +-------------+  +--->| Section address |-----+     |                  |
	       +-------------+       |             |       +-----------------+           |                  |
				     +-------------+       |                 |           |                  |
							   +-----------------+           |                  |
											 +------------------+
#+end_example

这里的区别在于 _PMD_ 现在包含指向 _物理区段的指针_ 。另外，偏移量占据了 _21位_ 而不是12位
#+begin_example
  因为需要21位来编码2MB的范围
#+end_example
* 页表描述符
#+begin_example
  可能会问MMU如何知道PMD项目是指向PTE还是物理2MB区段的？

  为了回答这个问题，需要更仔细地看一下页表项的结构
#+end_example

页表中的项目称为 _描述符_ 。描述符具有特殊的格式：

#+begin_example
			     Descriptor format
  `+------------------------------------------------------------------------------------------+
   | Upper attributes | Address (bits 47:12) | Lower attributes | Block/table bit | Valid bit |
   +------------------------------------------------------------------------------------------+
   63                 47                     11                 2                 1           0
#+end_example

关键是要理解每个描述符总是指向对齐的内容（可以是物理页、区段或层次结构中的下一个页表）。这意味着 _描述符中存储的地址_ 的 _最后12位_ *始终为0* 。这也意味着MMU可以使用这些位来存储更有用的信息，这正是它所做的

描述符中各位的含义：
+ *位 0*  ：对于所有 *有效* 的描述符，此位必须设置为 _1_
  #+begin_example
    如果在转换过程中MMU遇到非有效的描述符，将生成同步异常

    然后内核应处理此异常，分配一个新页并准备正确的描述符

    稍后将详细了解其工作原理
  #+end_example
+ *位 1* ： 指示当前描述符是指向层次结构中的 *下一个页表* 的描述符（称此类描述符为 _表描述符_ ），还是指向 *物理页或区段* 的描述符（称此类描述符为 _块描述符_ ）
+ *位 [11:2]* ：
  + 对于表描述符，这些位被忽略
  + 对于块描述符：它们包含一些属性，比如控制映射的页 _是否可缓存_ 、 _可执行_ 等
+ *位 [47:12]* ：存储描述符指向的 _地址_ 
  #+begin_example
    如前所述，只需存储地址的位 [47:12]，因为其他位始终为0
  #+end_example
+ *位 [63:48]* ：另一组属性位
* 页面属性配置

#+begin_example
  正如在前面的部分中提到的，每个块描述符包含一组属性，用于控制各种虚拟页面的参数

  然而，对于我们的讨论来说，最重要的属性并不直接在描述符中配置

  相反，ARM处理器实现了一种技巧，可以在描述符属性部分节省一些空间
#+end_example

ARM.v8架构引入了 _mair_el1寄存器_ 。该寄存器由8个部分组成，每个部分都有8个比特位。每个部分配置了一组常用的属性。然后， _描述符_ 仅指定 _mair部分_ 的 *索引* ，而不是直接指定所有属性。这样可以在描述符中仅使用 _3个比特位_ 来引用mair部分

#+begin_example
  mair部分中每个比特位的含义在AArch64参考手册的第2609页上有描述

  在RPi OS中，我们仅使用了一些可用的属性选项
#+end_example

以下是准备mair寄存器值的代码：

#+begin_src c 
  /*
   ,* Memory region attributes:
   ,*
   ,*   n = AttrIndx[2:0]
   ,*            n    MAIR
   ,*   DEVICE_nGnRnE    000    00000000
   ,*   NORMAL_NC        001    01000100
   ,*/
  #define MT_DEVICE_nGnRnE         0x0
  #define MT_NORMAL_NC            0x1
  #define MT_DEVICE_nGnRnE_FLAGS        0x00
  #define MT_NORMAL_NC_FLAGS          0x44
  #define MAIR_VALUE            (MT_DEVICE_nGnRnE_FLAGS << (8 * MT_DEVICE_nGnRnE)) | (MT_NORMAL_NC_FLAGS << (8 * MT_NORMAL_NC))
#+end_src

在这里，只使用了mair寄存器中可用的8个槽位中的2个。第一个对应于 _设备内存_ ，第二个对应于 _普通非缓存内存_ 。 _MT_DEVICE_nGnRnE_ 和 _MT_NORMAL_NC_ 是将在 _块描述符_ 中使用的 *索引* ，而  _MT_DEVICE_nGnRnE_FLAGS_ 和 _MT_NORMAL_NC_FLAGS_ 是 *存储* 在 _mair_el1寄存器_ 的前两个槽位中的值 
* 内核 VS 用户 虚拟内存
在打开MMU之后，每次内存访问都必须使用虚拟内存而不是物理内存。这个事实的一个结果是 *内核本身必须准备好使用虚拟内存并维护自己的页表集合*

#+begin_example
  一种可能的解决方案是每次从用户模式切换到内核模式时重新加载pgd寄存器

  但问题是切换pgd是非常昂贵的操作，因为它需要使所有缓存失效

  考虑到需要多频繁地从用户模式切换到内核模式，这种解决方案将使缓存完全无效，因此在操作系统开发中从不使用这种解决方案
#+end_example

相反，操作系统的做法是将地址空间分为两个部分： _用户空间_ 和 _内核空间_

#+begin_example
  32位体系结构通常将地址空间的前3GB分配给用户程序，将最后1GB保留给内核

  64位体系结构在这方面更加有利，因为它们具有巨大的地址空间

  更重要的是：ARM.v8体系结构带有一种原生功能，可以用来轻松实现用户/内核地址分割
#+end_example

有两个寄存器可以保存PGD的地址： _ttbr0_el1_ 和 _ttbr1_el1_ 。前面提到我们只使用了64位地址中的48位，因此上面的16位可以在转换过程中用来区分ttbr0和ttbr1：
+ 如果上面的16位全为0，则使用存储在ttbr0_el1中的PGD地址
+ 如果地址以0xffff开头（前16位全为1），则选择存储在ttbr1_el1中的PGD地址

体系结构还确保在 _EL0下运行的进程_ 永远无法访问以 _0xffff开头的虚拟地址_ ，否则会 _生成_ *同步异常*

#+begin_example
  从这个描述中，可以轻松推断：

  内核PGD的指针存储在ttbr1_el1中，并在内核的整个生命周期中保持不变

  而ttbr0_el1用于存储当前用户进程的PGD
#+end_example

这种方法的一个隐藏的结论是所有绝对内核地址必须以 _0xffff开头_ 。在RPi OS源代码中有两个地方处理了这个问题：
1. 在 _链接脚本_ 中，将镜像的基地址指定为0xffff000000000000。这会使编译器认为镜像将加载到0xffff000000000000地址，因此无论何时需要生成绝对地址，它都会生成正确的地址
   #+begin_example
     链接脚本还有一些其他更改，将在后面讨论它们
   #+end_example
2. 硬编码了绝对内核基地址：在定义 _设备基地址_ 的 *头文件* 中。现在，将从0xffff00003F000000开始访问所有设备内存
   #+begin_example
     当然，为了使其正常工作，首先需要映射内核需要访问的所有内存

     下面，将详细探讨创建此映射的代码
   #+end_example
* 初始化内核页面表
在引导过程的早期阶段，需要处理 *创建* _内核页表_ 的任务。这个过程始于 _boot.S_ 文件。在切换到EL1并清空BSS之后，会调用 _create_page_tables_ 函数。接下来逐行分析这个函数：

#+begin_src asm 
  __create_page_tables:
	  mov    x29, x30                        // save return address
#+end_src

首先，该函数保存了 _x30寄存器_ （链接寄存器）。因为将从 __create_page_tables 调用其他函数，x30寄存器会被覆盖

#+begin_example
  通常做法是把 x30寄存器保存在栈上，但是由于：
  1. 在__create_page_tables执行期间不会使用递归
  2. 没有其他人会使用x29寄存器

  因此这种简单的保留链接寄存器的方法也能很好地工作
#+end_example

#+begin_src asm 
	  adrp    x0, pg_dir
	  mov    x1, #PG_DIR_SIZE
	  bl     memzero
#+end_src

接下来，清除初始页表区域。在这里需要理解的重要事情是 _该区域的位置_ 以及 _如何知道它的大小_ ：
+ 初始页表区域在 _链接脚本_ 中定义：这意味着在 _内核映像_ 本身中为该区域分配了位置
+ 计算该区域的大小稍微有些棘手，需要了解初始内核页表的结构：
  + 所有的映射都位于 _1 GB_ 的区域内（这是RPi内存的大小），一个PGD描述符可以覆盖 _2^39 = 512 GB_ ，一个PUD描述符可以覆盖 _2^30 = 1 GB_ 的连续虚拟映射区域
    #+begin_example
      这些值是根据PGD和PUD索引在虚拟地址中的位置计算得出的

      这意味着只需要一个PGD和一个PUD来映射整个RPi内存
    #+end_example
  + 更重要的是，PGD和PUD都只包含一个描述符。即使只有一个PUD条目，那么也必须有一个单独的PMD表，该条目将指向该表
    #+begin_example
      单个PMD条目覆盖2 MB，一个PMD中有512个条目，所以整个PMD表覆盖了与单个PUD描述符相同的1 GB内存
    #+end_example
  + 需要映射1 GB的内存区域，而这是2 MB的倍数 ：可以使用 _区块映射_ 。这意味着 *根本不需要PTE* 
    #+begin_example
      因此，总共需要3个页面：一个用于PGD，一个用于PUD，一个用于PMD

      这恰好是初始页表区域的大小
    #+end_example

  现在暂时先离开 ___create_page_tables_ 函数，看一下两个关键的宏： _create_table_entry_ 和 _create_block_map_

** create_table_entry宏

负责 *分配* 新的页表（可以是PGD或PUD）：
#+begin_src asm 
	  .macro    create_table_entry, tbl, virt, shift, tmp1, tmp2
	  lsr    \tmp1, \virt, #\shift
	  and    \tmp1, \tmp1, #PTRS_PER_TABLE - 1            // table index
	  add    \tmp2, \tbl, #PAGE_SIZE
	  orr    \tmp2, \tmp2, #MM_TYPE_PAGE_TABLE
	  str    \tmp2, [\tbl, \tmp1, lsl #3]
	  add    \tbl, \tbl, #PAGE_SIZE                    // next level table page
	  .endm
#+end_src

这个宏接受以下参数：
+ tbl : 指向需要分配新表的内存区域的指针
+ virt : 当前正在映射的虚拟地址
+ shift : 应用于虚拟地址以提取当前表索引的位移量（对于PGD是39，对于PUD是30）
+ tmp1, tmp2 : 临时寄存器
 
这个宏非常重要，所以将花一些时间来理解它

#+begin_src asm 
	  lsr    \tmp1, \virt, #\shift
	  and    \tmp1, \tmp1, #PTRS_PER_TABLE - 1            // table index
#+end_src

前两行负责从 _虚拟地址_ 中 *提取* _表索引_ 。首先进行 _右移_ 操作，以 *去除* _索引右侧的所有位_ ，然后使用 _与位操作_ 来 *去除* _索引左侧的所有位_ 

#+begin_src asm
	  add    \tmp2, \tbl, #PAGE_SIZE
#+end_src

然后计算下一个页表的地址：

#+begin_example
  在这里，使用的约定是初始页表都位于一个连续的内存区域中

  简单地假设下一个页表在层级结构中将与当前页表相邻
#+end_example

#+begin_src asm 
	  orr    \tmp2, \tmp2, #MM_TYPE_PAGE_TABLE
#+end_src

接下来，将层级中的下一个页表的指针转换为一个表描述符（描述符的低两位必须设置为1）

#+begin_src asm
	  str    \tmp2, [\tbl, \tmp1, lsl #3]
#+end_src

然后，将 _描述符_ *存储* 在 _当前页表_ 中。这里使用之前计算的索引找到表中的正确位置

#+begin_src asm 
	  add    \tbl, \tbl, #PAGE_SIZE                    // next level table page
#+end_src

最后，将 _tbl参数_  *更改* 为 _指向层次结构中的下一个页表_ 

#+begin_example
  这一步不是必须的，但如果再次调用create_table_entry来为层次结构中的下一个表分配空间，就无需对tbl参数进行任何调整

  这正是create_pgd_entry宏所做的，它只是一个分配PGD和PUD的包装器
#+end_example

** create_block_map宏
正如猜测的那样，这个宏负责 *填充* _PMD表的条目_ 。代码如下所示：

#+begin_src asm 
	  .macro    create_block_map, tbl, phys, start, end, flags, tmp1
	  lsr    \start, \start, #SECTION_SHIFT
	  and    \start, \start, #PTRS_PER_TABLE - 1            // table index
	  lsr    \end, \end, #SECTION_SHIFT
	  and    \end, \end, #PTRS_PER_TABLE - 1                // table end index
	  lsr    \phys, \phys, #SECTION_SHIFT
	  mov    \tmp1, #\flags
	  orr    \phys, \tmp1, \phys, lsl #SECTION_SHIFT            // table entry
  9999:    str    \phys, [\tbl, \start, lsl #3]                // store the entry
	  add    \start, \start, #1                    // next entry
	  add    \phys, \phys, #SECTION_SIZE                // next block
	  cmp    \start, \end
	  b.ls    9999b
	  .endm
#+end_src

这里的参数略有不同：
+ tbl: 指向PMD表的指针
+ phys: 要映射的物理区域的起始地址
+ start:  要映射的第一个section的虚拟地址
+ end: 要映射的最后一个section的虚拟地址
+ flags: 需要复制到块描述符的低属性中的标志位
+ tmp1: 临时寄存器

#+begin_src asm 
	  lsr    \start, \start, #SECTION_SHIFT
	  and    \start, \start, #PTRS_PER_TABLE - 1            // table index
#+end_src

这两行代码从 _起始虚拟地址_ 中 *提取* 了 _表索引_ 。这与之前在create_table_entry宏中所做的方式完全相同 

#+begin_src asm 
	  lsr    \end, \end, #SECTION_SHIFT
	  and    \end, \end, #PTRS_PER_TABLE - 1                // table end index
#+end_src

对结束地址进行相同的操作。现在，start和end都包含了PMD表中对应原始地址的索引，而不是虚拟地址

#+begin_src asm 
	  lsr    \phys, \phys, #SECTION_SHIFT
	  mov    \tmp1, #\flags
	  orr    \phys, \tmp1, \phys, lsl #SECTION_SHIFT            // table entry
#+end_src

接下来，会准备并将 _块描述符_ *存储* 在 _tmp1变量_ 中。为了准备描述符，首先对 _phys参数_ 进行 _右移_ ，然后再进行 _左移_ ，并使用 _orr指令_ 与 _flags参数_ 合并

#+begin_example
  为什么必须将地址来回移动 ？ 答案是：
  
  1. 这样清除了物理地址中的前21位
  2. 使宏通用化，可以用于任何地址，而不仅仅是每一段的第一个地址 
#+end_example

#+begin_src asm 
  9999:    str    \phys, [\tbl, \start, lsl #3]                // store the entry
	  add    \start, \start, #1                    // next entry
	  add    \phys, \phys, #SECTION_SIZE                // next block
	  cmp    \start, \end
	  b.ls    9999b
#+end_src

函数的最后部分在一个循环中执行：
1. 将当前描述符存储在PMD表的正确索引位置
2. 将当前索引增加1，并更新描述符，使其指向下一个节
3. 重复这个过程，直到当前索引等于最后一个索引

** 映射内核和内核堆栈
#+begin_example
  现在，当你理解了create_table_entry和create_block_map宏的工作原理后，理解__create_page_tables函数的其余部分将变得简单明了
#+end_example

#+begin_src asm 
	  adrp    x0, pg_dir
	  mov    x1, #VA_START
	  create_pgd_entry x0, x1, x2, x3
#+end_src
在这里，创建了 _PGD_ 和 _PUD_ 。将它们配置为从 _VA_START虚拟地址_ 开始进行映射。由于create_table_entry宏的语义，当create_pgd_entry完成后，x0将包含层次结构中下一个表的地址，即PMD：

#+begin_src asm 
	  /* Mapping kernel and init stack*/
	  mov     x1, xzr                            // start mapping from physical offset 0
	  mov     x2, #VA_START                        // first virtual address
	  ldr    x3, =(VA_START + DEVICE_BASE - SECTION_SIZE)        // last virtual address
	  create_block_map x0, x1, x2, x3, MMU_FLAGS, x4
#+end_src


接下来，创建了整个内存的虚拟映射，但排除了 _设备寄存器区域_ 。使用 _MMU_FLAGS_ 常量作为 _flags参数_ ，这将所有的节区标记为正常的非缓存内存

#+begin_example
  请注意，MMU_FLAGS常量中也指定了MM_ACCESS标志

  如果没有这个标志，每次内存访问都会引发同步异常
#+end_example

** 映射设备内存

#+begin_src asm 
	  /* Mapping device memory*/
	  mov     x1, #DEVICE_BASE                    // start mapping from device base address
	  ldr     x2, =(VA_START + DEVICE_BASE)                // first virtual address
	  ldr    x3, =(VA_START + PHYS_MEMORY_SIZE - SECTION_SIZE)    // last virtual address
	  create_block_map x0, x1, x2, x3, MMU_DEVICE_FLAGS, x4
#+end_src

设备寄存器区域被映射过程与之前的内核内存区域被映射完全相同，只是现在使用不同的起始地址、结束地址和标志位

#+begin_src asm 
	  mov    x30, x29                        // restore return address
	  ret
#+end_src

最后，函数恢复了链接寄存器并返回给调用者

* 配置页表翻译

现在页面表已创建，再次回到el1_entry函数。但在打开MMU之前还有一些工作要做：

#+begin_src asm 
	  mov    x0, #VA_START
	  add    sp, x0, #LOW_MEMORY
#+end_src

更新init任务的堆栈指针。现在它使用的是虚拟地址，而不是物理地址

#+begin_example
  因此，只能在MMU打开后使用
#+end_example

#+begin_src asm 
	  adrp    x0, pg_dir
	  msr    ttbr1_el1, x0
#+end_src

_ttbr1_el1_ 被更新为指向先前填充的 _PGD表_

#+begin_src asm 
	  ldr    x0, =(TCR_VALUE)
	  msr    tcr_el1, x0
#+end_src

_tcr_el1寄存器_ 负责配置MMU的一些通用参数

#+begin_example
  例如，在这里配置内核和用户页表都应该使用4KB的页面大小
#+end_example

#+begin_src asm 
	  ldr    x0, =(MAIR_VALUE)
	  msr    mair_el1, x0
#+end_src

在前面已经讨论过了 mair_el1 寄存器，这里设置它的值

#+begin_src asm 
	  ldr    x2, =kernel_main

	  mov    x0, #SCTLR_MMU_ENABLED
	  msr    sctlr_el1, x0

	  br     x2
#+end_src

_msr sctlr_el1, x0_ 是实际启用MMU的指令。现在可以跳转到kernel_main函数了

#+begin_example
  一个有趣的问题是为什么不能直接执行br kernel_main指令呢？

  事实上，在MMU启用之前，我们一直在使用物理内存，内核加载在物理偏移0处，这意味着当前程序计数器非常接近0

  启用MMU不会更新程序计数器。如果现在执行br kernel_main指令，该指令将使用相对于当前程序计数器的偏移量，并跳转到未开启MMU时kernel_main所在的位置

  而ldr x2, =kernel_main则会加载x2寄存器的值为kernel_main函数的绝对地址

  由于在链接脚本中将图像的基地址设置为0xffff000000000000，kernel_main函数的绝对地址将从内核镜像开始处的偏移量加上0xffff000000000000来计算，这正是我们所需要的

  另一个需要理解的重要事项是为什么ldr x2, =kernel_main指令必须在我们启用MMU之前执行

  原因是ldr指令也使用pc相对偏移量，因此如果我们尝试在MMU开启后但在跳转到镜像基地址之前执行此指令，该指令将引发页错误
#+end_example

* 加载用户级别进程代码
#+begin_example
  如果使用的是真正的操作系统，可能会期望它能够从文件系统中读取您的程序并执行它

  但对于Rpi OS操作系统而言，情况有所不同，它目前还不具备文件系统支持

  之前并不关注这个事实，因为用户进程与内核共享相同的地址空间

  现在情况发生了变化，每个进程应该有自己独立的地址空间，因此需要找出如何存储用户程序，以便稍后加载到新创建的进程中
#+end_example
最终实现的一个技巧是将用户程序存储在内核映像的一个单独部分中。下面是负责执行此操作的链接脚本的相关部分：

#+begin_example
      . = ALIGN(0x00001000);
      user_begin = .;
      .text.user : { build/user* (.text) }
      .rodata.user : { build/user* (.rodata) }
      .data.user : { build/user* (.data) }
      .bss.user : { build/user* (.bss) }
      user_end = .;
#+end_example

这里使用了一种约定，即用户级别的源代码应该定义在以 _user_ 前缀命名的文件中。然后，链接脚本可以将所有与用户相关的代码隔离在一个连续的区域中，并定义 _user_begin_ 和 _user_end_ 变量，用于标记此区域的起始和结束位置。通过这种方式，可以简单地将user_begin和user_end之间的所有内容复制到新分配的进程地址空间中，从而模拟加载用户程序

#+begin_example
  这种方法足够简单，并且对于当前的目的效果很好

  在实现文件系统支持之后，将摆脱这种临时解决方案，能够加载ELF文件
#+end_example

目前有两个文件被编译到用户区域中：
+ _user_sys.S_ ：该文件包含系统调用包装函数的定义
  #+begin_example
    RPi操作系统仍然支持与之前相同的系统调用，只是将使用fork系统调用而不是clone系统调用

    fork会复制进程的虚拟内存，而这正是现在想要尝试的
  #+end_example
+ _user.c_ ：用户程序的源代码
  #+begin_example
    几乎与之前使用的代码相同
  #+end_example

* 创建第一个用户级别进程
与以前类似， _move_to_user_mode_ 函数负责创建第一个用户进程。从一个内核进程中调用此函数：

#+begin_src c 
  void kernel_process(){
	  printf("Kernel process started. EL %d\r\n", get_el());
	  unsigned long begin = (unsigned long)&user_begin;
	  unsigned long end = (unsigned long)&user_end;
	  unsigned long process = (unsigned long)&user_process;
	  int err = move_to_user_mode(begin, end - begin, process - begin);
	  if (err < 0){
		  printf("Error while moving process to user mode\n\r");
	  }
  }
#+end_src

现在需要三个参数来调用 move_to_user_mode函数：
1. 用户代码区域的起始指针
2. 区域的大小
3. 启动函数的偏移量

#+begin_example
  这些信息是基于前面讨论过的user_begin和user_end变量进行计算得出的
#+end_example

move_to_user_mode 函数：

#+begin_src c 
  int move_to_user_mode(unsigned long start, unsigned long size, unsigned long pc)
  {
	  struct pt_regs *regs = task_pt_regs(current);
	  regs->pstate = PSR_MODE_EL0t;
	  regs->pc = pc;
	  regs->sp = 2 *  PAGE_SIZE;
	  unsigned long code_page = allocate_user_page(current, 0);
	  if (code_page == 0)    {
		  return -1;
	  }
	  memcpy(code_page, start, size);
	  set_pgd(current->mm.pgd);
	  return 0;
  }
#+end_src

现在逐行检查代码：

#+begin_src c 
  struct pt_regs *regs = task_pt_regs(current);
  regs->pstate = PSR_MODE_EL0t;
#+end_src

首先获取一个指向 _pt_regs区域的指针_ ，并设置 _pstate_ ，这样在kernel_exit之后将进入EL0模式

#+begin_src c
  regs->pc = pc;
#+end_src

现在，pc指向用户区域中启动函数的 *偏移量*

#+begin_src c 
  regs->sp = 2 *  PAGE_SIZE;
#+end_src

这里有一个简单的约定，即用户程序不会超过1页的大小。所以从第二页开始分配给栈

#+begin_src c 
  unsigned long code_page = allocate_user_page(current, 0);
  if (code_page == 0)    {
	  return -1;
  }
#+end_src

_allocate_user_page函数_ 预留 1个内存页面，并将其 *映射* 到 _提供的虚拟地址_ 作为第二个参数。在映射过程中，它 *填充* 了与 _当前进程关联的页表_

#+begin_example
稍后将详细研究这个函数的工作原理
#+end_example

#+begin_src c 
  memcpy(code_page, start, size);
#+end_src

接下来，将把整个用户区域复制到新的地址空间（刚刚映射的页面中）

#+begin_example
从偏移量0开始，这样用户区域中的偏移量将成为实际的起始虚拟地址！
#+end_example

#+begin_src c 
  set_pgd(current->mm.pgd);
#+end_src

最后，调用 _set_pgd函数_ ，它会 *更新* _ttbr0_el1寄存器_ ，从而 *激活* _当前进程的转换表_ 

** TLB （地址转换缓存）

如果查看 _set_pgd函数_ ，会看到在设置 _ttbr0_el1_ 之后，它还清空了TLB（Translation Lookaside Buffer，地址转换缓存）。TLB是一个专门用于存储物理页和虚拟页映射关系的缓存
+ 当某个虚拟地址第一次映射到物理地址时，该映射关系会被存储在TLB中
+ 下次访问相同的页面时，就不再需要进行完整的页表查找
+ 因此，在更新页表之后清空TLB是非常有意义的，否则更改将不会应用于已存储在TLB中的页面。

#+begin_example
  通常情况下，为了简化操作，尽量避免使用所有的缓存，但是如果没有TLB，任何内存访问都会变得极其低效，而且我认为完全禁用TLB可能是不可能的

  此外，除了在切换ttbr0_el1之后需要清空它之外，TLB不会给操作系统增加其他复杂性
#+end_example

* 映射虚拟地址
前面已经看到了 allocate_user_page 函数怎么使用，现在是时候来看看它是怎么实现的：

#+begin_src c 
  unsigned long allocate_user_page(struct task_struct *task, unsigned long va) {
	  unsigned long page = get_free_page();
	  if (page == 0) {
		  return 0;
	  }
	  map_page(task, va, page);
	  return page + VA_START;
  }
#+end_src

这个函数分配一个新的页面，将其映射到提供的虚拟地址，并返回页面的指针。现在说 _指针_ 时，需要区分三种不同的指针：
1. 指向 _物理页面_ 的指针
2. 指向 _内核地址空间_ 中的指针
3. 指向 _用户地址空间_ 中的指针

#+begin_example
  这三种不同的指针都可以指向相同的内存位置

  在这里，page变量是一个物理指针，而返回值是内核地址空间中的指针
#+end_example

这个指针可以很容易地计算，因为在boot.S中将 _整个物理内存_ *线性映射* 到了 _VA_START虚拟地址_ 开始的位置。也不需要担心分配新的内核页表，因为在boot.S中已经将所有的内存映射完成。但是，仍然需要 *创建* _用户映射_ ，这是在 _map_page函数_ 中完成的，接下来将探讨这个函数：

#+begin_src c 
  void map_page(struct task_struct *task, unsigned long va, unsigned long page){
	  unsigned long pgd;
	  if (!task->mm.pgd) {
		  task->mm.pgd = get_free_page();
		  task->mm.kernel_pages[++task->mm.kernel_pages_count] = task->mm.pgd;
	  }
	  pgd = task->mm.pgd;
	  int new_table;
	  unsigned long pud = map_table((unsigned long *)(pgd + VA_START), PGD_SHIFT, va, &new_table);
	  if (new_table) {
		  task->mm.kernel_pages[++task->mm.kernel_pages_count] = pud;
	  }
	  unsigned long pmd = map_table((unsigned long *)(pud + VA_START) , PUD_SHIFT, va, &new_table);
	  if (new_table) {
		  task->mm.kernel_pages[++task->mm.kernel_pages_count] = pmd;
	  }
	  unsigned long pte = map_table((unsigned long *)(pmd + VA_START), PMD_SHIFT, va, &new_table);
	  if (new_table) {
		  task->mm.kernel_pages[++task->mm.kernel_pages_count] = pte;
	  }
	  map_table_entry((unsigned long *)(pte + VA_START), va, page);
	  struct user_page p = {page, va};
	  task->mm.user_pages[task->mm.user_pages_count++] = p;
  }
#+end_src

_map_page函数_ 在某种程度上重复了在 ___create_page_tables函数_ 中的操作：它 *分配* 并 *填充* 了一个 _页面表层级结构_ 。然而，有三个重要的区别：
1. 现在使用C语言而不是汇编语言
2. map_page函数映射单个页面而不是整个内存
3. 使用普通的页面映射而不是段映射

在这个过程中涉及到两个重要的函数： _map_table_  和 _map_table_entry_ 。map_table 代码如下：

#+begin_src c 
  unsigned long map_table(unsigned long *table, unsigned long shift, unsigned long va, int* new_table) {
	  unsigned long index = va >> shift;
	  index = index & (PTRS_PER_TABLE - 1);
	  if (!table[index]){
		  ,*new_table = 1;
		  unsigned long next_level_table = get_free_page();
		  unsigned long entry = next_level_table | MM_TYPE_PAGE_TABLE;
		  table[index] = entry;
		  return next_level_table;
	  } else {
		  ,*new_table = 0;
	  }
	  return table[index] & PAGE_MASK;
  }
#+end_src


该函数具有以下参数：
+ *table* ：指向父级页表的指针。假设该页表已经分配，但可能为空
+ *shift* ：用于从提供的虚拟地址中提取表索引的值
+ *va* ：虚拟地址本身
+ *new_table* ：这是一个输出参数。如果已经分配了新的子表，则设置为 _1_ ；否则设置为 _0_  

可以将这个函数视为 _create_table_entry 宏_ 的引申。它从虚拟地址中提取表索引，并在父表中准备一个指向子表的描述符

#+begin_example
  但与 create_table_entry 宏不同，不能假设子表应与父表相邻 相反，依赖 get_free_table 函数返回可用的任意页

  还可能出现子表已经分配的情况（如果子页表覆盖了先前已分配另一页的区域）。在这种情况下，将 new_table 设置为0，并从父表中读取子页表的地址
#+end_example

map_page 函数调用 map_table 三次：一次用于 _PGD_ ，一次用于 _PUD_ ，一次用于 _PMD_ 。最后一次调用分配 _PTE_  并在 _PMD_ 中 *设置* 一个 _描述符_ 。接下来，会调用 _map_table_entry 函数_ ：

#+begin_src c 
  void map_table_entry(unsigned long *pte, unsigned long va, unsigned long pa) {
	  unsigned long index = va >> PAGE_SHIFT;
	  index = index & (PTRS_PER_TABLE - 1);
	  unsigned long entry = pa | MMU_PTE_FLAGS;
	  pte[index] = entry;
  }
#+end_src

map_table_entry 函数从 _虚拟地址_ 中 *提取* _PTE 索引_ ，然后准备并 *设置* _PTE 描述符_ 

#+begin_example
  类似于在 create_block_map 宏中所做的操作
#+end_example

这就是有关用户页表分配的内容，但是 map_page 还负责其他更重要的任务：
+ 它跟踪在虚拟地址映射过程中已经分配的页面。所有这些页面都存储在 _kernel_pages 数组_ 中
  #+begin_example
    需要这个数组来在任务退出后清理已分配的页面
  #+end_example
+ 还有一个 _user_pages 数组_ ，也由 map_page 函数填充。这个数组 *存储* 了 _进程虚拟页面_ 和 _物理页面之间_ 的对应关系
  #+begin_example
    需要这些信息来在 fork 过程中能够复制进程的虚拟内存
  #+end_example

* fork进程

