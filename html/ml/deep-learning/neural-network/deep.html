<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>深度神经网络</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Wu, Shanliang" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="../css/main.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="./shallow.html"> UP </a>
 |
 <a accesskey="H" href="./neural-network.html"> HOME </a>
</div><div id="content">
<h1 class="title">深度神经网络</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org5053be7">深层神经网络</a></li>
<li><a href="#org8c06538">前向传播</a></li>
<li><a href="#orgb413eac">反向传播</a></li>
<li><a href="#orgef9340f">深层网络中的前向传播</a></li>
<li><a href="#org2cc3998">核对矩阵的维数</a></li>
<li><a href="#org4016cf9">为什么使用深层表示？</a></li>
<li><a href="#org48a15ed">搭建神经网络块</a></li>
<li><a href="#org4b63a83">参数 VS 超参数</a></li>
</ul>
</div>
</div>
<pre class="example">
  目前为止学习了只有一个单独隐藏层的神经网络的正向传播和反向传播，还有逻辑回归

  并且还学到了向量化，这在随机初始化权重时是很重要

  接下来要做的是把这些理念集合起来，这样就可以执行你自己的深度神经网络
</pre>
<div id="outline-container-org5053be7" class="outline-2">
<h2 id="org5053be7">深层神经网络</h2>
<div class="outline-text-2" id="text-org5053be7">
<p>
复习下前面的内容：
</p>

<p>
逻辑回归和一个隐藏层的神经网络，结构如下：
</p>


<div class="figure">
<p><img src="../pic/7c1cc04132b946baec5487ba68242362.png" alt="7c1cc04132b946baec5487ba68242362.png" width="70%" />
</p>
</div>

<p>
注意，神经网络的层数是这么定义的： <b>从左到右，由0开始定义</b> ，比如上边右图 \(x_1\) , \(x_2\) , \(x_3\) 这层是第 \(0\) 层，这层右边的隐藏层是第 \(1\) 层，由此类推。如下图左边是两个隐藏层的神经网络，右边是5个隐藏层的神经网络：
</p>


<div class="figure">
<p><img src="../pic/be71cf997759e4aeaa4be1123c6bb6ba.png" alt="be71cf997759e4aeaa4be1123c6bb6ba.png" width="70%" />
</p>
</div>

<p>
严格上来说逻辑回归也是一个一层的神经网络，而上边右图是一个深得多的模型：
</p>
<ul class="org-ul">
<li>有一个隐藏层的神经网络，就是一个两层神经网络</li>
<li>当算神经网络的层数时，不算输入层，只算 <span class="underline">隐藏层</span> 和 <span class="underline">输出层</span></li>
</ul>

<pre class="example">
    但是在过去的几年中，研究者已经意识到有一些函数，只有非常深的神经网络能学会，而更浅的模型则办不到

    尽管对于任何给定的问题很难去提前预测到底需要多深的神经网络，可以先去尝试逻辑回归，尝试一层然后两层隐含层

    然后把隐含层的数量看做是另一个可以自由选择大小的超参数，再保留交叉验证数据上评估，或者用开发集来评估
</pre>

<p>
现在来看下深度学习的符号定义：
</p>


<div class="figure">
<p><img src="../pic/9927bcb34e8e5bfe872937fccd693081.png" alt="9927bcb34e8e5bfe872937fccd693081.png" width="70%" />
</p>
</div>

<pre class="example">
    上图是一个4层的神经网络，有 3 个隐藏层

    可以看到，第一层有5个神经元数目，第二层5个，第三层3个
</pre>

<p>
用 \(L\) 表示层数： \(\mathbf{L} = 4\) , 输入层的索引为 \(0\) ：
</p>
<ul class="org-ul">
<li>第一个隐藏层 \(n^{[1]} = 5\) 表示有5个隐藏神经元</li>
<li>同理 \(n^{[2]} = 5\) , \(n^{[3]} = 3\) , \(n^{[4]} = 1\) （输出单元为1）</li>
<li>输入层 \(n^{[0]} = n_x = 3\)</li>
</ul>

<p>
在不同层所拥有的神经元的数目，对于每层 \(a^{[l]}\) 都用来记作 \(l\) 层激活后结果
</p>

<pre class="example">
    会在后面看到在正向传播时，最终能会计算出这个结果
</pre>

<ul class="org-ul">
<li>通过用激活函数 \(g\) 计算 \(z^{[l]}\) ，激活函数也被索引为层数 \(l\) , 然后用 \(w^{[l]}\) 来记作在 \(l\) 层计算值的 <b>权重</b></li>
<li>类似的也有 \(b^{[l]}\)</li>
<li>输入的特征记作 \(x\) ，但是 \(x\) 同样也是 \(0\) 层的激活函数，所以 \(x = a^{[0]}\)</li>
<li>最后一层 \(a^{[L]}\) 等于这个神经网络所预测的输出结果</li>
</ul>
</div>
</div>

<div id="outline-container-org8c06538" class="outline-2">
<h2 id="org8c06538">前向传播</h2>
<div class="outline-text-2" id="text-org8c06538">
<pre class="example">
    之前学习了构成深度神经网络的基本模块

    比如每一层都有前向传播步骤以及一个相反的反向传播步骤
</pre>

<p>
前向传播：输入 \(a^{[l-1]}\) ，输出 \(a^{[l]}\) ，缓存为 \(z^{[l]}\) ；从实现的角度来可以缓存下 \(w^{[l]}\) 和 \(b^{[l]}\) ，这样更容易在不同的环节中调用函数
</p>


<div class="figure">
<p><img src="../pic/7cfc4b5fe94dcd9fe7130ac52701fed5.png" alt="7cfc4b5fe94dcd9fe7130ac52701fed5.png" width="70%" />
</p>
</div>

<p>
前向传播的步骤：
</p>

\begin{equation}
z^{[l]} = W^{[l]} \cdot a^{[l-1]} + b^{[l]} \\ 
a^{[l]} = g^{[l]}(z^{[l]}) 
\end{equation}

<p>
向量化实现过程：
</p>

\begin{equation}
Z^{[l]} = W^{[l]} \cdot A^{[l-1]} + b^{[l]} \\
A^{[l]} = g^{[l]}(Z^{[l]})
\end{equation} 

<p>
前向传播需要喂入 \(A^{[0]}\) 也就是 \(X\) ，来初始化；初始化的是第一层的输入值。\(a^{[0]}\) 对应于一个训练样本的输入特征，而 \(A^{[0]}\) 对应于一整个训练样本的输入特征
</p>
<pre class="example">
    所以这就是这条链的第一个前向函数的输入，重复这个步骤就可以从左到右计算前向传播 
</pre>
</div>
</div>

<div id="outline-container-orgb413eac" class="outline-2">
<h2 id="orgb413eac">反向传播</h2>
<div class="outline-text-2" id="text-orgb413eac">
<p>
输入为 \(\mathrm{d} a^{[l]}\) ，输出为 \(\mathrm{d} a^{[l-1]}\) ，\(\mathrm{d} w^{[l]}\) ,  \(\mathrm{d} b^{[l]}\)   
</p>


<div class="figure">
<p><img src="../pic/c13d2a8fa258125a5398030c97101ee1.png" alt="c13d2a8fa258125a5398030c97101ee1.png" width="70%" />
</p>
</div>

<p>
反向传播的步骤：
</p>

\begin{equation}
\mathrm{d} z^{[l]} = \mathrm{d} a^{[l]} \ast g^{[l]^{'}}(z^{[l]}) 
\end{equation} 

\begin{equation}
\mathrm{d} w^{[l]} =  \mathrm{d} z^{[l]} \cdot a^{[l-1]}
\end{equation}

\begin{equation}
\mathrm{d} b^{[l]} =  \mathrm{d} z^{[l]} 
\end{equation}

\begin{equation}
\mathrm{d} a^{[l-1]} =  w^{[l]T} \cdot \mathrm{d} z^{[l]}
\end{equation}

\begin{equation}
\mathrm{d} z^{[l]} =  w^{[l+1]T}\mathrm{d} z^{[l+1]} \ast g^{[l]^{'}}(z^{[l]}) 
\end{equation}

<pre class="example">
  式子（5）由式子（4）带入式子（1）得到，前四个式子就可实现反向函数
</pre>

<p>
向量化实现过程：
</p>

\begin{equation}
\mathrm{d} Z^{[l]} = \mathrm{d} A^{[l]} \ast g^{[l]^{'}}(Z^{[l]})
\end{equation}

\begin{equation}
\mathrm{d} W^{[l]} =  \frac{1}{m}\mathrm{d} Z^{[l]} \cdot A^{[l-1]T}
\end{equation}

\begin{equation}
\mathrm{d} b^{[l]} =  \frac{1}{m} np.sum(\mathrm{d} z^{[l]}, \text{axis} = 1, \text{keepdims} = True)
\end{equation}

\begin{equation}
\mathrm{d} A^{[l-1]} =  W^{[l]T} \cdot \mathrm{d} Z^{[l]}
\end{equation}

<p>
总结：
</p>


<div class="figure">
<p><img src="../pic/53a5b4c71c0facfc8145af3b534f8583.png" alt="53a5b4c71c0facfc8145af3b534f8583.png" width="70%" />
</p>
</div>

<ul class="org-ul">
<li>第一层可能有一个 \(ReLU\) 激活函数，第二层为另一个 \(ReLU\) 激活函数，第三层可能是\(sigmoid\) 函数（如果做二分类的话），输出值为 \(\hat{y}\) ，用来计算损失</li>
<li>这样就可以向后迭代进行反向传播求导来求 \(\mathrm{d} w^{[3]}\) , \(\mathrm{d} b^{[3]}\) , \(\mathrm{d}w^{[2]}\) , \(\mathrm{d} b^{[2]}\) , \(\mathrm{d} w^{[1]}\) , \(\mathrm{d} b^{[1]}\)</li>
<li>在计算的时候，缓存会把 \(z^{[1]}\) , \(z^{[2]}\) , \(z^{[3]}\) 传递过来，然后回传 \(\mathrm{d} a^{[2]}\) ,  \(\mathrm{d} a^{[1]}\)</li>
<li>也可以计算 \(\mathrm{d}a^{[0]}\) ，但实际不会使用它</li>
</ul>

<pre class="example">
    这里讲述了一个三层网络的前向和反向传播
</pre>
</div>
</div>

<div id="outline-container-orgef9340f" class="outline-2">
<h2 id="orgef9340f">深层网络中的前向传播</h2>
<div class="outline-text-2" id="text-orgef9340f">
<pre class="example">
    跟往常一样，先来看对其中一个训练样本如何应用前向传播，之后讨论向量化的版本
</pre>

<ul class="org-ul">
<li>第一层需要计算 \(z^{[l]} = w^{[1]}x + b^{[1]}\) ， \(a^{[1]} = g^{[1]}(z^{[1]})\) （ \(x\) 可以看做 \(a^{[0]}\) ）</li>
<li>第二层需要计算 \(z^{[2]} = w^{[2]}a^{[1]} + b^{[2]}\) ， \(a^{[2]} = g^{[2]}(z^{[2]})\)</li>
<li>以此类推</li>
<li>第四层为 \(z^{[4]} = w^{[4]}a^{[3]} + b^{[4]}\) ， \(a^{[4]} = g^{[4]}(z^{[4]})\)</li>
</ul>
<p>
前向传播可以归纳为多次迭代 \(z^{[l]} = w^{[l]}a^{[l-1]} + b^{[l]}\) ， \(a^{[l]} = g^{[l]}(z^{[l]})\)  
</p>


<div class="figure">
<p><img src="../pic/faf2d5a697d1bd75aee46865f3a73a25.png" alt="faf2d5a697d1bd75aee46865f3a73a25.png" width="70%" />
</p>
</div>

<p>
向量化实现过程可以写成：
</p>
\begin{equation}
Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]} \\ 
A^{[l]} = g^{[l]}(Z^{[l]}) \\
A^{[0]} = X 
\end{equation}

<p>
这里不得不用一个显式for循环，从第一层开始接着一层层去计算直到第 \(L\) 层
</p>
</div>
</div>

<div id="outline-container-org2cc3998" class="outline-2">
<h2 id="org2cc3998">核对矩阵的维数</h2>
<div class="outline-text-2" id="text-org2cc3998">
<p>
当实现深度神经网络的时候，其中一个常用的检查代码是否有错的方法就是拿出一张纸过一遍算法中矩阵的维数：
</p>
<ul class="org-ul">
<li>\(w\) 的维度是（下一层的维数，前一层的维数），即 \(w^{[l]}:(n^{[l]}, n^{[l-1]})\)</li>
<li>\(b\) 的维度是（下一层的维数，1），即: \(b^{[l]}: (n^{[l]}, 1)\)</li>
<li>类似地： \(z^{[l]}, a^{[l]}: (n^{[l]}, 1)\)</li>
<li>\(\mathrm{d} w^{[l]}\) 与 \(w^{[l]}\) 维度相同</li>
<li>\(\mathrm{d} b^{[l]}\) 与 \(b^{[l]}\) 维度相同</li>
</ul>

<p>
\(w\) 和 \(b\) 向量化维度不变，但 \(z\), \(a\) 以及 \(x\) 的维度向量化后会改变
</p>


<div class="figure">
<p><img src="../pic/5ee7a8073518e36a98d4225eaf0f3063.png" alt="5ee7a8073518e36a98d4225eaf0f3063.png" width="70%" />
</p>
</div>

<p>
向量化后：
</p>

<ul class="org-ul">
<li>\(Z^{[l]}\) 可以看成由每一个单独的 \(z^{[l]}\) 叠加而得到 \(Z^{l} = (z^{[l](1)}, z^{[l](2)}, \ldots , z^{[l](m)})\) , \(m\) 为训练集大小，所以的 \(Z^{[l]}\) 维度不再是 \((n^{[l]}, 1)\) ，而是 \((n^{[l]}, m)\)</li>
<li>同样地： \(A^{[l]}: (n^{[l]}, m)\) , 特别地： \(A^{[0]} = X: (n^{[0]}, m)\)</li>
</ul>


<div class="figure">
<p><img src="../pic/fb680729409dc3912fd5a3d0c13b620a.png" alt="fb680729409dc3912fd5a3d0c13b620a.png" width="70%" />
</p>
</div>

<p>
在你做深度神经网络的反向传播时，一定要确认所有的矩阵维数是前后一致的，可以大大提高代码通过率
</p>

<pre class="example">
    接下来是为什么深层的网络在很多问题上比浅层的好
</pre>
</div>
</div>

<div id="outline-container-org4016cf9" class="outline-2">
<h2 id="org4016cf9">为什么使用深层表示？</h2>
<div class="outline-text-2" id="text-org4016cf9">
<pre class="example">
    我们都知道深度神经网络能解决好多问题

    其实并不需要很大的神经网络，但是得有深度，得有比较多的隐藏层

    一起来看几个例子来帮助理解，为什么深度神经网络会很好用
</pre>

<p>
深度网络在计算什么？
</p>


<div class="figure">
<p><img src="../pic/563823fb44e05835948366f087f17e5c.png" alt="563823fb44e05835948366f087f17e5c.png" width="70%" />
</p>
</div>

<p>
如果在建一个人脸识别或是人脸检测系统，深度神经网络所做的事就是输入一张脸部的照片。可以把深度神经网络的第一层，当成一个 <b>特征探测器</b> 或者边缘探测器。我会建一个大概有20个隐藏单元的深度神经网络，隐藏单元就是这些图里这些小方块（第一张大图）
</p>

<pre class="example">
    举个例子，这个小方块（第一行第一列）就是一个隐藏单元，它会去找这张照片里“|”边缘的方向

    那么这个隐藏单元（第四行第四列），可能是在找（“—”）水平向的边缘在哪里

    之后的课程里，会讲专门做这种识别的卷积神经网络，到时候会细讲
</pre>


<p>
为什么小单元是这么表示的？可以先把神经网络的第一层当作看图，然后去找这张照片的各个边缘。把照片里组成边缘的像素们放在一起看，这就把探测到的边缘组合成 <span class="underline">面部的不同部分</span> （第二张大图）
</p>

<pre class="example">
    比如说，可能有一个神经元会去找眼睛的部分，另外还有别的在找鼻子的部分

    然后把这许多的边缘结合在一起，就可以开始检测人脸的不同部分
</pre>

<p>
后再把这些部分放在一起，比如鼻子眼睛下巴，就可以识别或是探测不同的人脸（第三张大图） 。可以直觉上把这种神经网络的前几层当作探测简单的函数，比如边缘，之后把它们跟后几层结合在一起，那么总体上就能学习更多复杂的函数
</p>

<pre class="example">
    这些图的意义，在学习卷积神经网络的时候再深入了解
</pre>

<p>
还有一个技术性的细节需要理解的是，边缘探测器其实相对来说都是针对照片中非常小块的面积。就像这块（第一行第一列），都是很小的区域。面部探测器就会针对于大一些的区域
</p>

<pre class="example">
    但是主要的概念是，一般会从比较小的细节入手，比如边缘

    然后再一步步到更大更复杂的区域，比如一只眼睛或是一个鼻子

    再把眼睛鼻子装一块组成更复杂的部分
</pre>


<div class="figure">
<p><img src="../pic/595d105074eda2e4a11da9592fd5e444.png" alt="595d105074eda2e4a11da9592fd5e444.png" width="70%" />
</p>
</div>

<p>
这种从简单到复杂的金字塔状表示方法或者组成方法，也可以应用在图像或者人脸识别以外的其他数据上
</p>

<pre class="example">
    比如想要建一个语音识别系统的时候，需要解决的就是如何可视化语音

    比如输入一个音频片段，那么神经网络的第一层可能就会去先开始试着探测比较低层次的音频波形的一些特征，音调是变高了还是低了，分辨白噪音，咝咝咝的声音，或者音调
    选择这些相对程度比较低的波形特征，然后把这些波形组合在一起就能去探测声音的基本单元

    在语言学中有个概念叫做音位，比如说单词ca，c的发音，“嗑”就是一个音位，a的发音“啊”是个音位，t的发音“特”也是个音位
    有了基本的声音单元以后，组合起来，就能识别音频当中的单词
    单词再组合起来就能识别词组，再到完整的句子
</pre>


<div class="figure">
<p><img src="../pic/bbdec09feac2176ad9578e93c1ee8c04.png" alt="bbdec09feac2176ad9578e93c1ee8c04.png" width="70%" />
</p>
</div>

<p>
所以深度神经网络的这许多隐藏层中，较早的前几层能学习一些低层次的简单特征，等到后几层，就能把简单的特征结合起来，去探测更加复杂的东西
</p>

<pre class="example">
    比如录在音频里的单词、词组或是句子，然后就能运行语音识别了

    同时所计算的之前的几层，也就是相对简单的输入函数，比如图像单元的边缘什么的

    到网络中的深层时，实际上就能做很多复杂的事，比如探测面部或是探测单词、短语或是句子
</pre>

<p>
有些人喜欢把深度神经网络和人类大脑做类比，这些神经科学家觉得人的大脑也是先探测简单的东西
</p>

<pre class="example">
    眼睛看得到的边缘，然后组合起来才能探测复杂的物体，比如脸

    这种深度学习和人类大脑的比较，有时候比较危险

    但是不可否认的是，对大脑运作机制的认识很有价值

    有可能大脑就是先从简单的东西，比如边缘着手，再组合成一个完整的复杂物体

    这类简单到复杂的过程，同样也是其他一些深度学习的灵感来源
</pre>

<ul class="org-ul">
<li><b>Small</b> ：隐藏单元的数量相对较少</li>
<li><b>Deep</b> ：隐藏层数目比较多</li>
</ul>

<p>
深层的网络隐藏单元数量相对较少，隐藏层数目较多。如果浅层的网络想要达到同样的计算结果则需要 <b>指数级增长</b> 的单元数量才能达到
</p>

<pre class="example">
    为啥需要指数级别呢？ 来看另外一个，关于神经网络为何有效的理论
</pre>

<p>
另外一个理论来源于电路理论，它和能够用电路元件计算哪些函数有着分不开的联系。根据不同的基本逻辑门，譬如 <span class="underline">与门</span> 、 <span class="underline">或门</span> 、 <span class="underline">非门</span> 
</p>

<pre class="example">
    在非正式的情况下，这些函数都可以用相对较小，但很深的神经网络来计算

    小在这里的意思是隐藏单元的数量相对比较小

    但是如果用浅一些的神经网络计算同样的函数，也就是说在不能用很多隐藏层时，会需要成指数增长的单元数量才能达到同样的计算结果
</pre>


<div class="figure">
<p><img src="../pic/b409b7c0d05217ea37f0036691c891ca.png" alt="b409b7c0d05217ea37f0036691c891ca.png" width="70%" />
</p>
</div>

<p>
假设想要对输入特征计算异或或是奇偶性，可以算 \(x_1\mathbf{XOR}x_2\mathbf{XOR}x_3\mathbf{XOR} \ldots x_n\) ，假设有 \(n_x\) 个特征，如果画一个异或的树图，先要计算 \(x_1\) , \(x_2\) 的异或，然后 \(x_3\) 是和 \(x_4\) 。技术上来如果只用 <span class="underline">或门</span> ，还有 <span class="underline">非门</span> 的话，可能会需要几层才能计算异或函数，但是用相对小的电路，应该就可以计算异或了。然后可以继续建这样的一个异或树图（上图左），那么最后会得到这样的电路来输出结果 \(y\) , \(\hat{y} = y\) 也就是输入特征的异或，或是奇偶性，要计算异或关系。这种树图对应网络的深度应该是 \(O(\log{n})\) ，那么节点的数量和电路部件，也就是是门的数量并不会很大，也不需要太多门去计算异或
</p>

<p>
但是如果不能使用多隐层的神经网络的话，比如被迫只能用单隐藏层来计算的话，这里全部都指向从这些隐藏单元到后面这里，再输出 \(y\) ，那么要计算奇偶性，或者异或关系函数就需要这一隐层（上图右方框部分）的单元数呈指数增长才行，因为本质上来说需要列举耗尽 \(2^n\) 种可能的配置，或是 \(2^n\) 种输入比特的配置。异或运算的最终结果是 \(1\) 或 \(0\) ，那么最终就会需要一个隐藏层，其中单元数目随输入比特指数上升。精确的说应该是个 \(2^{n-1}\) 隐藏单元数，也就是 \(O(2^n)\) 
</p>

<pre class="example">
    这种电路理论，对训练直觉思维没那么有用

    但这个结果人们还是经常提到的，用来解释为什么需要更深层的网络

    此外 深度学习 这个名字挺唬人的，这些概念以前都统称为有很多隐藏层的神经网络

    但是深度学习听起来多高大上，这个词流传出去以后，这是神经网络的重新包装或是多隐藏层神经网络的重新包装，激发了大众的想象力

    抛开这些公关概念重新包装不谈，深度网络确实效果不错，有时候人们还是会按照字面意思钻牛角尖，非要用很多隐层

    但是当开始解决一个新问题时，通常会从logistic回归开始
    再试试一到两个隐层
    把隐藏层数量当作参数、超参数一样去调试，这样去找比较合适的深度

    但是近几年以来，有一些人会趋向于使用非常非常深邃的神经网络，比如好几打的层数
    某些问题中只有这种网络才是最佳模型
</pre>
</div>
</div>

<div id="outline-container-org48a15ed" class="outline-2">
<h2 id="org48a15ed">搭建神经网络块</h2>
<div class="outline-text-2" id="text-org48a15ed">
<pre class="example">
  已经看到过正向反向传播的基础组成部分了，它们也是深度神经网络的重要组成部分

  现在来用它们建一个深度神经网络
</pre>


<div class="figure">
<p><img src="../pic/2922198c51ca18fb64dcc7f4cc46d507.png" alt="2922198c51ca18fb64dcc7f4cc46d507.png" width="70%" />
</p>
</div>

<p>
这是一个层数较少的神经网络，选择其中一层（方框部分），从这一层的计算着手：
</p>
<ul class="org-ul">
<li>在第 \(l\) 层有参数 \(W^{[l]}\) 和 \(b^{[l]}\)</li>
<li>正向传播里有输入的激活函数，输入是前一层 \(a^{[l-1]}\) ，输出是 \(a^{[l]}\)</li>
<li>根据 \(z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}\) , \(a^{[l]} = g^{[l]}(z^{[l]}\) ，这就是如何从输入 \(a^{[l-1]}\) 走到输出的 \(a^{[l]}\)</li>
<li>之后可以把 \(z^{[l]}\) 的值缓存起来，因为缓存的 \(z^{[l]}\) 对以后的反向传播的步骤非常有用</li>
</ul>

<p>
接下来是反向步骤步骤，同样也是第 \(l\) 层的计算，会需要实现一个函数输入为 \(\mathrm{d} a^{[l]}\) ，输出的函数 \(\mathrm{d} a^{[l-1]}\) 
</p>
<ul class="org-ul">
<li>输入在这里其实是 \(\mathrm{d} a^{[l]}\) 以及所缓存的值 \(z^{[l]}\) (之前已经计算好)</li>
<li>也需要输出所以需要的梯度 \(\mathrm{d} W^{[l]}\) 和 \(\mathrm{d} b^{[l]}\) ，这是为了实现梯度下降学习</li>
</ul>

<pre class="example">
这就是基本的正向步骤的结构，它成为称为正向函数，类似的在反向步骤中会称为反向函数
</pre>


<div class="figure">
<p><img src="../pic/f1c14c92b1735648c05db7741f7d2871.png" alt="f1c14c92b1735648c05db7741f7d2871.png" width="70%" />
</p>
</div>


<p>
总结: 
</p>
<ul class="org-ul">
<li>在 \(l\) 层，会有正向函数 ，输入 \(a^{[l-1]}\) 并且输出 \(a^{[l]}\) ，为了计算结果需要用 \(W^{[l]}\) 和 \(b^{[l]}\) ，以及输出到缓存的 \(z^{[l]}\)</li>
<li>用作反向传播的反向函数，是另一个函数，输入 \(\mathrm{d} a^{[l]}\) ，输出 \(\mathrm{d} a^{[l-1]}\) 
<ol class="org-ol">
<li>在第二个方块里根据 \(W^{[l]}\) 和 \(b^{[l]}\) ，可以算的是 \(\mathrm{d} z^{[l]}\)</li>
<li>第三个方块中，这个反向函数可以计算输出 \(\mathrm{d} W^{[l]}\) 和 \(\mathrm{d} b^{[l]}\)</li>
</ol></li>
</ul>

<pre class="example">
  这里用红色箭头标注标注反向步骤
</pre>

<p>
如果实现了这两个函数（正向和反向），然后神经网络的计算过程会是这样的：
</p>


<div class="figure">
<p><img src="../pic/0b59199835620b12c781b3190a3fca1c.png" alt="0b59199835620b12c781b3190a3fca1c.png" width="70%" />
</p>
</div>


<ul class="org-ul">
<li>把输入特征 \(a^{[0]}\) ，放入第一层并计算第一层的激活函数，用 \(a^{[1]}\) 表示，需要 \(W^{[1]}\) 和 \(b^{[1]}\) 来计算，之后缓存 $z^{[1]}$值</li>
<li>之后把 \(a^{[1]}\) 喂到第二层，需要用到 \(W^{[2]}\) 和 \(b^{[2]}\) 和计算第二层的激活函数 $a^{[2]} $</li>
<li>后面几层以此类推，直到最后算出了 \(a^{[L]}\) ，第 \(L\) 层的最终输出值 \(\hat{y}\)</li>
</ul>

<pre class="example">
  在这些过程里缓存了所有的 z 值，这就是正向传播的步骤
</pre>

<p>
对反向传播的步骤而言，需要算一系列的反向迭代：
</p>
<ul class="org-ul">
<li>把 \(\mathrm{d} a^{[L]}\) 值放在这里，然后这个方块负责计算 \(\mathrm{d} a^{[L-1]}\) 值</li>
<li>以此类推，直到得到 \(\mathrm{d} a^{[2]}\) 和 \(\mathrm{d} a^{[1]}\)</li>
<li><p>
还可以计算多一个输出值 \(\mathrm{d} a^{[0]}\) ，这其实是输入特征的导数
</p>
<pre class="example">
    起码对于训练监督学习的权重不算重要，可以止步于此
</pre></li>
<li>反向传播步骤中也会输出 \(\mathrm{d} W^{[l]}\) 和 \(\mathrm{d} b^{[l]}\)</li>
</ul>

<pre class="example">
  目前为止算好了所有需要的导数，稍微填一下这个流程图
</pre>


<div class="figure">
<p><img src="../pic/be2f6c7a8ff3c58e952208d5d59b19ce.png" alt="be2f6c7a8ff3c58e952208d5d59b19ce.png" width="70%" />
</p>
</div>

<p>
神经网络的一步训练包含了 ：
</p>
<ol class="org-ol">
<li>从 \(a^{[0]}\) 开始，也就是 \(x\) 经过一系列正向传播计算得到 \(\hat{y}\)</li>
<li>再用输出值计算这个（第二行最后方块），再实现反向传播。现在就有所有的导数项了</li>
<li>\(W\) 也会在每一层被更新为 \(W = W - \alpha\mathrm{d}W\) ， \(b\) 也一样 \(b = b - \alpha\mathrm{d} b\) ，反向传播就都计算完毕</li>
</ol>

<pre class="example">
这是神经网络一个梯度下降循环
</pre>
</div>
</div>

<div id="outline-container-org4b63a83" class="outline-2">
<h2 id="org4b63a83">参数 VS 超参数</h2>
</div>
</div>
<div id="postamble" class="status">

		  <br/>
		  <div class='ds-thread'></div>
		  <script>
		  var duoshuoQuery = {short_name:'klose911'};
		  (function() {
					  var dsThread = document.getElementsByClassName('ds-thread')[0];
					  dsThread.setAttribute('data-thread-key', document.title);
					  dsThread.setAttribute('data-title', document.title);
					  dsThread.setAttribute('data-url', window.location.href);
					  var ds = document.createElement('script');
					  ds.type = 'text/javascript';ds.async = true;
					  ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
					  ds.charset = 'UTF-8';
					  (document.getElementsByTagName('head')[0] 
						|| document.getElementsByTagName('body')[0]).appendChild(ds);
					  })();
		  </script>
		  <script>
		  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
		  ga('create', 'UA-90850421-1', 'auto');
		  ga('send', 'pageview');
		  </script>
</div>
</body>
</html>
