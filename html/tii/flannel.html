<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Flannel网络</title>
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Wu, Shanliang" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="css/main.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Flannel网络</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">环境+提示</a></li>
<li><a href="#sec-2">Kubernetes Cluster中的几个 <b>网络</b></a></li>
<li><a href="#sec-3">平坦的Flannel网络</a>
<ul>
<li><a href="#sec-3-1">Kubenetes安装后的网络状态</a>
<ul>
<li><a href="#sec-3-1-1">修改docker default配置</a></li>
<li><a href="#sec-3-1-2">在etcd中初始化flannel网络数据</a></li>
<li><a href="#sec-3-1-3">启动flanneld</a></li>
<li><a href="#sec-3-1-4">创建flannel.1 网络设备、更新路由信息</a></li>
<li><a href="#sec-3-1-5">平坦的flannel network</a></li>
</ul>
</li>
<li><a href="#sec-3-2">flannel网络通信原理</a>
<ul>
<li><a href="#sec-3-2-1">从Pod出发</a></li>
<li><a href="#sec-3-2-2">docker0与flannel.1之间的包转发</a></li>
<li><a href="#sec-3-2-3">flannel.1设备以及flanneld的功用</a></li>
<li><a href="#sec-3-2-4">kernel的vxlan封包</a></li>
<li><a href="#sec-3-2-5">kernel的vxlan拆包</a></li>
</ul>
</li>
<li><a href="#sec-3-3">Pod内到外部网络</a></li>
</ul>
</li>
<li><a href="#sec-4"><span class="underline">不真实</span> 的Service网络</a></li>
</ul>
</div>
</div>
<p>
<span class="underline">Kubernetes</span> 支持 <b>Flannel</b> 、 <span class="underline">Calico</span> 、 <span class="underline">Weave</span> network等多种 <span class="underline">cni</span> 网络Drivers，但由于学习过程使用的是第一个cluster的Flannel网络，这里的网络原理只针对k8s+Flannel网络
</p>
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">环境+提示</h2>
<div class="outline-text-2" id="text-1">
<p>
凡涉及到Docker、Kubernetes这类正在开发的开源项目的文章，随着K8s以及flannel的演化，本文中的一些说法可能不再正确。注意：阅读此类技术文章务必结合 <b>环境</b> 
</p>

<p>
这里使用的环境就是第一次建立k8s cluster的环境：
</p>

<div class="org-src-container">

<pre class="src src-sh">$ kube-apiserver --version
Kubernetes v1.3.7

$ /opt/bin/flanneld -version
0.5.5

$ /opt/bin/etcd -version
etcd Version: 3.0.12
Git SHA: 2d1e2e8
Go Version: go1.6.3
Go OS/Arch: linux/amd64
</pre>
</div>


<p>
整个集群搭建在 <span class="underline">阿里云</span> 上，每个ECS上的OS及kernel版本： <span class="underline">Ubuntu 14.04.4 LTS，3.19.0-70-generic</span> 
</p>

<p>
在测试环境，有两个node： <span class="underline">master</span> node和一个 <span class="underline">minion</span> node。master node参与workload的调度。所以基本可以认为有两个minion node即可
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">Kubernetes Cluster中的几个 <b>网络</b></h2>
<div class="outline-text-2" id="text-2">
<p>
k8s cluster采用的是默认安装，即直接使用了配置脚本中( <span class="underline">kubernetes/cluster/ubuntu/config-default.sh</span> )自带的一些参数，比如：
</p>

<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">&#25688;&#33258;kubernetes/cluster/ubuntu/config-default.sh</span>

<span style="color: #b0c4de;">export</span> <span style="color: #eedd82;">nodes</span>=${<span style="color: #eedd82;">nodes</span>:-<span style="color: #ffa07a;">"root@master_node_ip root@minion_node_ip"</span>}
<span style="color: #b0c4de;">export</span> <span style="color: #eedd82;">SERVICE_CLUSTER_IP_RANGE</span>=${<span style="color: #eedd82;">SERVICE_CLUSTER_IP_RANGE</span>:-192.168.3.0/24}
<span style="color: #b0c4de;">export</span> <span style="color: #eedd82;">FLANNEL_NET</span>=${<span style="color: #eedd82;">FLANNEL_NET</span>:-172.16.0.0/16}
</pre>
</div>

<p>
从这里能够识别出三个 <b>网络</b> ：
</p>
<ol class="org-ol">
<li><b>node</b> network：承载kubernetes集群中各个 <span class="underline">物理</span> Node(master和minion)通信的网络
<ul class="org-ul">
<li>node间通过 <span class="underline">本地局域网</span> （无论是物理的还是虚拟的）通信
</li>
</ul>
</li>
<li><b>service</b> network：由kubernetes集群中的 <span class="underline">Services</span> 所组成的网络
<ul class="org-ul">
<li>每个新创建的service会被分配一个service IP，在当前集群中，这个IP的分配范围是 <span class="underline">192.168.3.0/24</span> 。不过这个IP并不 <span class="underline">真实</span> ，更像一个 <b>占位符</b> 并且只有入口流量，所谓的network也是 <span class="underline">名不符实</span> 的
</li>
</ul>
</li>
<li><b>flannel</b> network： 即 <span class="underline">Pod</span> 网络，集群中承载各个Pod相互通信的网络
<ul class="org-ul">
<li>cluster中各个Pod要实现相互通信，必须走这个网络，无论是在同一node上的Pod还是跨node的Pod。cluster中，flannel net的分配范围是： <span class="underline">172.16.0.0/16</span>
</li>
</ul>
</li>
</ol>

<p>
Service network，看 <span class="underline">cluster-ip</span> 一列：
</p>

<div class="org-src-container">

<pre class="src src-sh">$ kubectl get services
NAME           CLUSTER-IP      EXTERNAL-IP   PORT(S)     AGE
index-api      192.168.3.168   &lt;none&gt;        30080/TCP   18d
kubernetes     192.168.3.1     &lt;none&gt;        443/TCP     94d
my-nginx       192.168.3.179   &lt;nodes&gt;       80/TCP      90d
nginx-kit      192.168.3.196   &lt;nodes&gt;       80/TCP      12d
rbd-rest-api   192.168.3.22    &lt;none&gt;        8080/TCP    60d
</pre>
</div>

<p>
Flannel network，看 <span class="underline">IP</span> 那列:
</p>

<div class="org-src-container">

<pre class="src src-sh">$ kubectl get pod -o wide
NAME                           READY     STATUS    RESTARTS   AGE       IP            NODE
my-nginx-2395715568-gpljv      1/1       Running   6          91d       172.16.99.3   {master node ip}
nginx-kit-3872865736-rc8hr     2/2       Running   0          12d       172.16.57.7   {minion node ip}
... ...
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">平坦的Flannel网络</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1">Kubenetes安装后的网络状态</h3>
<div class="outline-text-3" id="text-3-1">
<p>
首先来看看 <span class="underline">kube-up.sh</span> 在安装k8s集群时对各个K8s Node都动了什么手脚
</p>
</div>

<div id="outline-container-sec-3-1-1" class="outline-4">
<h4 id="sec-3-1-1">修改docker default配置</h4>
<div class="outline-text-4" id="text-3-1-1">
<p>
在ubuntu 14.04下，docker的配置都在 <span class="underline">/etc/default/docker</span> 文件中。如果曾经修改过该文件，那么 <span class="underline">kube-up.sh</span> 脚本方式安装完kubernetes后，会发现/etc/default/docker已经变样了，只剩下了一行：
</p>
<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node:</span>
<span style="color: #eedd82;">DOCKER_OPTS</span>=<span style="color: #ffa07a;">" -H tcp://127.0.0.1:4243 -H unix:///var/run/docker.sock --bip=172.16.99.1/24 --mtu=1450"</span>

<span style="color: #ff4500;">#</span><span style="color: #ff4500;">minion node:</span>
<span style="color: #eedd82;">DOCKER_OPTS</span>=<span style="color: #ffa07a;">" -H tcp://127.0.0.1:4243 -H unix:///var/run/docker.sock --bip=172.16.57.1/24 --mtu=1450"</span>
</pre>
</div>

<p>
kube-up.sh修改了Docker daemon的 <span class="underline">-bip</span> 选项，使得每个节点上docker守护进程为以后启动的容器在 <b>fannel subnet</b> 范围以内分配IP地址
</p>
</div>
</div>

<div id="outline-container-sec-3-1-2" class="outline-4">
<h4 id="sec-3-1-2">在etcd中初始化flannel网络数据</h4>
<div class="outline-text-4" id="text-3-1-2">
<p>
多个节点上的flanneld依赖一个 <b>etcd集群</b> 来做集中配置服务：
</p>
<ul class="org-ul">
<li>etcd保证了所有节点上flanned所看到的配置是一致的
</li>
<li>每个节点上的flanned监听etcd上的数据变化，实时感知集群中node的变化
</li>
</ul>

<p>
可以通过 <span class="underline">etcdctl</span> 查询到这些配置数据：
</p>
<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node:</span>

<span style="color: #ff4500;">#</span><span style="color: #ff4500;">flannel network&#37197;&#32622;</span>
$ etcdctl --endpoints http://127.0.0.1:{etcd listen port} get  /coreos.com/network/config
{<span style="color: #ffa07a;">"Network"</span>:<span style="color: #ffa07a;">"172.16.0.0/16"</span>, <span style="color: #ffa07a;">"Backend"</span>: {<span style="color: #ffa07a;">"Type"</span>: <span style="color: #ffa07a;">"vxlan"</span>}}

$ etcdctl --endpoints http://127.0.0.1:{etcd listen port} ls  /coreos.com/network/subnets
/coreos.com/network/subnets/172.16.99.0-24
/coreos.com/network/subnets/172.16.57.0-24

<span style="color: #ff4500;">#</span><span style="color: #ff4500;">&#26576;&#19968;node&#19978;&#30340;flanne subnet&#21644;vtep&#37197;&#32622;</span>
$ etcdctl --endpoints http://127.0.0.1:{etcd listen port} get  /coreos.com/network/subnets/172.16.99.0-24
{<span style="color: #ffa07a;">"PublicIP"</span>:<span style="color: #ffa07a;">"{master node ip}"</span>,<span style="color: #ffa07a;">"BackendType"</span>:<span style="color: #ffa07a;">"vxlan"</span>,<span style="color: #ffa07a;">"BackendData"</span>:{<span style="color: #ffa07a;">"VtepMAC"</span>:<span style="color: #ffa07a;">"b6:bf:4c:81:cf:3b"</span>}}


<span style="color: #ff4500;"># </span><span style="color: #ff4500;">minion node:</span>
$ etcdctl --endpoints http://127.0.0.1:{etcd listen port} get  /coreos.com/network/subnets/172.16.57.0-24
{<span style="color: #ffa07a;">"PublicIP"</span>:<span style="color: #ffa07a;">"{minion node ip}"</span>,<span style="color: #ffa07a;">"BackendType"</span>:<span style="color: #ffa07a;">"vxlan"</span>,<span style="color: #ffa07a;">"BackendData"</span>:{<span style="color: #ffa07a;">"VtepMAC"</span>:<span style="color: #ffa07a;">"d6:51:2e:80:5c:69"</span>}}
</pre>
</div>


<p>
或用etcd提供的rest api：
</p>
<div class="org-src-container">

<pre class="src src-sh">$ curl -L http://127.0.0.1:{etcd listen port}/v2/keys/coreos.com/network/config
{<span style="color: #ffa07a;">"action"</span>:<span style="color: #ffa07a;">"get"</span>,<span style="color: #ffa07a;">"node"</span>:{<span style="color: #ffa07a;">"key"</span>:<span style="color: #ffa07a;">"/coreos.com/network/config"</span>,<span style="color: #ffa07a;">"value"</span>:<span style="color: #ffa07a;">"{\"Network\":\"172.16.0.0/16\", \"Backend\": {\"Type\": \"vxlan\"}}"</span>,<span style="color: #ffa07a;">"modifiedIndex"</span>:5,<span style="color: #ffa07a;">"createdIndex"</span>:5}}
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-3-1-3" class="outline-4">
<h4 id="sec-3-1-3">启动flanneld</h4>
<div class="outline-text-4" id="text-3-1-3">
<p>
kube-up.sh在每个Kubernetes节点上启动了一个 <span class="underline">flanneld</span> 的程序：
</p>
<div class="org-src-container">

<pre class="src src-sh">$ ps -ef | grep flanneld

<span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node:</span>
root      1151     1  0  2016 ?        00:02:34 /opt/bin/flanneld --etcd-endpoints=http://127.0.0.1:{etcd listen port} --ip-masq --iface={master node ip}

<span style="color: #ff4500;"># </span><span style="color: #ff4500;">minion node:</span>
root     11940     1  0  2016 ?        00:07:05 /opt/bin/flanneld --etcd-endpoints=http://{master node ip}:{etcd listen port} --ip-masq --iface={minion node ip}
</pre>
</div>

<p>
一旦flanneld启动，它将从etcd中读取配置，并请求获取一个租约，有效期目前是 <span class="underline">24hrs</span> ，并且监视etcd的数据更新。flanneld一旦获取subnet租约、配置完backend，它会将一些信息写入 <span class="underline">/run/flannel/subnet.env</span> 文件
</p>

<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node&#65306;</span>
$ cat /run/flannel/subnet.env
<span style="color: #eedd82;">FLANNEL_NETWORK</span>=172.16.0.0/16
<span style="color: #eedd82;">FLANNEL_SUBNET</span>=172.16.99.1/24
<span style="color: #eedd82;">FLANNEL_MTU</span>=1450
<span style="color: #eedd82;">FLANNEL_IPMASQ</span>=true

<span style="color: #ff4500;">#</span><span style="color: #ff4500;">minion node:</span>
$ cat /run/flannel/subnet.env
<span style="color: #eedd82;">FLANNEL_NETWORK</span>=172.16.0.0/16
<span style="color: #eedd82;">FLANNEL_SUBNET</span>=172.16.57.1/24
<span style="color: #eedd82;">FLANNEL_MTU</span>=1450
<span style="color: #eedd82;">FLANNEL_IPMASQ</span>=true
</pre>
</div>

<p>
flanneld的最大意义在于 <b>根据etcd中存储的全cluster的subnet信息，跨node传输flannel network中的数据包</b> ，这个后面会详细说明。
</p>
</div>
</div>

<div id="outline-container-sec-3-1-4" class="outline-4">
<h4 id="sec-3-1-4">创建flannel.1 网络设备、更新路由信息</h4>
<div class="outline-text-4" id="text-3-1-4">
<p>
各个node上的网络设备列表新增一个名为 <b>flannel.1</b> 的类型为 <span class="underline">vxlan</span> 的网络设备：
</p>

<div class="org-src-container">

<pre class="src src-sh">$ ip -d link show
<span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node:</span>

4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default
    link/ether b6:bf:4c:81:cf:3b brd ff:ff:ff:ff:ff:ff promiscuity 0
    vxlan id 1 local {master node local ip} dev eth0 port 0 0 nolearning ageing 300

<span style="color: #ff4500;">#</span><span style="color: #ff4500;">minion node:</span>

349: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default
    link/ether d6:51:2e:80:5c:69 brd ff:ff:ff:ff:ff:ff promiscuity 0
    vxlan id 1 local  {minion node local ip} dev eth0 port 0 0 nolearning ageing 300
</pre>
</div>

<p>
从 <span class="underline">flannel.1</span> 的设备信息来看，它似乎与 <span class="underline">eth0</span> 存在着某种 <b>bind</b> 关系。这是在其他 <span class="underline">bridge</span> 、 <span class="underline">veth</span> 设备描述信息中所没有的
</p>

<p>
<span class="underline">flannel.1</span> 设备的ip：
</p>
<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node:</span>

flannel.1 Link encap:Ethernet  HWaddr b6:bf:4c:81:cf:3b
          inet addr:172.16.99.0  Bcast:0.0.0.0  Mask:255.255.0.0
          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1
          RX packets:5993274 errors:0 dropped:0 overruns:0 frame:0
          TX packets:5829044 errors:0 dropped:292 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:1689890445 (1.6 GB)  TX bytes:1144725704 (1.1 GB)

<span style="color: #ff4500;">#</span><span style="color: #ff4500;">minion node:</span>

flannel.1 Link encap:Ethernet  HWaddr d6:51:2e:80:5c:69
          inet addr:172.16.57.0  Bcast:0.0.0.0  Mask:255.255.0.0
          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1
          RX packets:6294640 errors:0 dropped:0 overruns:0 frame:0
          TX packets:5755599 errors:0 dropped:25 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:989362527 (989.3 MB)  TX bytes:1861492847 (1.8 GB)
</pre>
</div>

<p>
可以看到两个节点上的 <span class="underline">flannel.1</span> 的ip与k8s集群为两个节点上分配subnet的ip范围是对应的
</p>

<p>
下面是两个节点上的当前路由表：
</p>
<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node:</span>

$ ip route
... ...
172.16.0.0/16 dev flannel.1  proto kernel  scope link  src 172.16.99.0
172.16.99.0/24 dev docker0  proto kernel  scope link  src 172.16.99.1
... ...

<span style="color: #ff4500;">#</span><span style="color: #ff4500;">minion node:</span>

$ ip route
... ...
172.16.0.0/16 dev flannel.1
172.16.57.0/24 dev docker0  proto kernel  scope link  src 172.16.57.1
... ...
</pre>
</div>

<p>
以上信息将为后续数据包传输分析打下基础
</p>
</div>
</div>

<div id="outline-container-sec-3-1-5" class="outline-4">
<h4 id="sec-3-1-5">平坦的flannel network</h4>
<div class="outline-text-4" id="text-3-1-5">
<p>
从以上kubernetes和flannel network安装之后获得的网络信息，能看出flannel network是一个 <b>flat network</b> 。在flannel：172.16.0.0/16这个大网下，每个kubernetes节点从中分配一个子网片段(/24)：
</p>

<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node&#65306;</span>
  --bip=172.16.99.1/24

<span style="color: #ff4500;">#</span><span style="color: #ff4500;">minion node&#65306;</span>
  --bip=172.16.57.1/24

root@node1:~# etcdctl --endpoints http://127.0.0.1:{etcd listen port} ls  /coreos.com/network/subnets
/coreos.com/network/subnets/172.16.99.0-24
/coreos.com/network/subnets/172.16.57.0-24
</pre>
</div>

<p>
用一张图来诠释可能更为直观：
</p>


<div class="figure">
<p><img src="pic/flat-flannel-network.png" alt="flat-flannel-network.png" width="70%" />
</p>
</div>

<p>
在平坦的flannel network中， <b>每个pod都会被分配唯一的ip地址，且每个k8s节点的subnet各不重叠</b> ，没有交集。不过这样的subnet分配模型也有一定弊端，那就是可能存在ip浪费： <span class="underline">一个node上有200多个flannel ip地址(xxx.xxx.xxx.xxx/24)，如果仅仅启动了几个Pod，那么其余ip就处于闲置状态</span>
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2">flannel网络通信原理</h3>
<div class="outline-text-3" id="text-3-2">

<div class="figure">
<p><img src="pic/kubernetes-flannel.png" alt="kubernetes-flannel.png" width="70%" />
</p>
</div>

<p>
如上图所示，来看看从 <span class="underline">pod1：172.16.99.8</span> 发出的数据包是如何到达 <span class="underline">pod3：172.16.57.15</span>
</p>
</div>

<div id="outline-container-sec-3-2-1" class="outline-4">
<h4 id="sec-3-2-1">从Pod出发</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
由于k8s更改了DOCKER<sub>OPTS，显式指定了</sub> <span class="underline">-bip</span> ，这个值与分配给该节点上的subnet的范围是一致的。这样一来，docker引擎每次创建一个容器，该容器被分配到的ip都在 <span class="underline">flannel subnet</span> 范围内
</p>

<p>
在Pod1下的某个容器内执行 <span class="underline">ping -c 3 172.16.57.15</span> ，数据包便开始了它在flannel network中的旅程
</p>

<p>
Pod是Kubernetes调度的基本单元。Pod内的多个容器共享一个 <span class="underline">network namespace</span> 。kubernetes在创建pod时，首先先创建 <span class="underline">pause</span> 容器，然后再以pause的 <span class="underline">network namespace</span> 为基础，创建pod内的其他容器（ <span class="underline">-net=container:xxx</span> ），这样pod内的所有容器便共享一个network namespace，这些容器间的访问直接通过localhost即可。比如pod下A容器启动了一个服务，监听8080端口，那么同一个pod下面的另外一个B容器通过访问 <span class="underline">localhost:8080</span> 即可访问到A容器下面的那个服务
</p>

<p>
看一下Pod1中某容器内的路由信息：
</p>
<div class="org-src-container">

<pre class="src src-sh">$ docker exec ba75f81455c7 ip route
default via 172.16.99.1 dev eth0
172.16.99.0/24 dev eth0  proto kernel  scope link  src 172.16.99.8
</pre>
</div>

<p>
目的地址 <span class="underline">172.16.57.15</span> 并不在直连网络中，因此数据包通过 <b>default路由</b> 出去。default路由的路由器地址是 <span class="underline">172.16.99.1</span> ，也就是上面的docker0 bridge的IP地址。相当于docker0 bridge以 <span class="underline">三层的工作模式</span> 直接接收到来自容器的数据包(而并非从bridge的二层端口接收)
</p>
</div>
</div>

<div id="outline-container-sec-3-2-2" class="outline-4">
<h4 id="sec-3-2-2">docker0与flannel.1之间的包转发</h4>
<div class="outline-text-4" id="text-3-2-2">
<p>
数据包到达docker0后，docker0的内核栈处理程序发现这个数据包的目的地址是 <span class="underline">172.16.57.15</span> ，并不是真的要送给自己，于是开始为该数据包找下一hop。根据master node上的路由表
</p>
<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node&#65306;</span>

$ ip route
... ...
172.16.0.0/16 dev flannel.1  proto kernel  scope link  src 172.16.99.0
172.16.99.0/24 dev docker0  proto kernel  scope link  src 172.16.99.1
... ...
</pre>
</div>

<p>
匹配到 <b>172.16.0.0/16</b> 这条路由！这是一条直连路由，数据包被直接送到 <span class="underline">flannel.1</span> 设备上
</p>
</div>
</div>

<div id="outline-container-sec-3-2-3" class="outline-4">
<h4 id="sec-3-2-3">flannel.1设备以及flanneld的功用</h4>
<div class="outline-text-4" id="text-3-2-3">
<p>
flannel.1是否会重复docker0的套路呢：包不是发给自己，转发数据包？会，也不会
</p>
<ul class="org-ul">
<li><b>会</b> ：flannel.1肯定要将包转发出去，因为毕竟包不是给自己的（包目的ip是 <span class="underline">172.16.57.15</span> , vxlan设备ip是 <span class="underline">172.16.99.0</span> ）
</li>
<li><b>不会</b> ：flannel.1不会走寻常套路去转发包，因为它是一个 <span class="underline">vxlan</span> 类型的设备，也称为 <span class="underline">virtual tunnel end point</span>
</li>
</ul>

<p>
那么它到底是怎么处理数据包的呢？这里涉及一些Linux内核对vxlan处理的内容
</p>

<p>
flannel.1收到数据包后，由于自己不是目的地，也要尝试将数据包重新发送出去。数据包沿着网络协议栈向下流动，在二层时需要封二层以太包，填写目的mac地址，这时一般应该发出 <span class="underline">arp：”who is 172.16.57.15″</span> 。但vxlan设备的特殊性就在于 <b>它并没有真正在二层发出这个arp包</b> ，因为下面的这个内核参数设置：
</p>

<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node:</span>
$ cat /proc/sys/net/ipv4/neigh/flannel.1/app_solicit
3
</pre>
</div>

<p>
而是由linux kernel引发一个 <span class="underline">L3 MISS</span> 事件并将arp请求发到 <b>用户空间的flanned</b> 程序 
</p>

<p>
flanned程序收到 <span class="underline">L3 MISS</span> 内核事件以及 <span class="underline">arp请求(who is 172.16.57.15)</span> 后，并不会向外网发送arp request，而是尝试 <b>从etcd查找该地址匹配的子网的vtep信息</b> 。在前面曾经展示过etcd中Flannel network的配置信息：
</p>
<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node:</span>

$ etcdctl --endpoints http://127.0.0.1:{etcd listen port} ls  /coreos.com/network/subnets
/coreos.com/network/subnets/172.16.99.0-24
/coreos.com/network/subnets/172.16.57.0-24

$ curl -L http://127.0.0.1:{etcd listen port}/v2/keys/coreos.com/network/subnets/172.16.57.0-24
{<span style="color: #ffa07a;">"action"</span>:<span style="color: #ffa07a;">"get"</span>,<span style="color: #ffa07a;">"node"</span>:{<span style="color: #ffa07a;">"key"</span>:<span style="color: #ffa07a;">"/coreos.com/network/subnets/172.16.57.0-24"</span>,<span style="color: #ffa07a;">"value"</span>:<span style="color: #ffa07a;">"{\"PublicIP\":\"{minion node local ip}\",\"BackendType\":\"vxlan\",\"BackendData\":{\"VtepMAC\":\"d6:51:2e:80:5c:69\"}}"</span>,<span style="color: #ffa07a;">"expiration"</span>:<span style="color: #ffa07a;">"2017-01-17T09:46:20.607339725Z"</span>,<span style="color: #ffa07a;">"ttl"</span>:21496,<span style="color: #ffa07a;">"modifiedIndex"</span>:2275460,<span style="color: #ffa07a;">"createdIndex"</span>:2275460}}
</pre>
</div>

<p>
flanneld从etcd中找到了答案：
</p>
<pre class="example">
subnet: 172.16.57.0/24
public ip: {minion node local ip}
VtepMAC: d6:51:2e:80:5c:69
</pre>
<p>
查看minion node上的信息，发现minion node上的flannel.1 设备mac就是 <span class="underline">d6:51:2e:80:5c:69</span> ：
</p>
<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">minion node:</span>

$ ip -d link show

349: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default
    link/ether d6:51:2e:80:5c:69 brd ff:ff:ff:ff:ff:ff promiscuity 0
    vxlan id 1 local 10.46.181.146 dev eth0 port 0 0 nolearning ageing 300
</pre>
</div>

<p>
接下来，flanned将查询到的信息放入master node的 <b>arp cache</b> 表中：
</p>

<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node:</span>

$ ip n | grep 172.16.57.15
172.16.57.15 dev flannel.1 lladdr d6:51:2e:80:5c:69 REACHABLE
</pre>
</div>
<p>
flanneld完成这项工作后，linux kernel就可以在arp table中找到 <span class="underline">172.16.57.15</span> 对应的mac地址并封装二层以太包了
</p>

<p>
到目前为止，封包如下图：
</p>

<div class="figure">
<p><img src="pic/flannel-network-inner-packet.png" alt="flannel-network-inner-packet.png" width="70%" />
</p>
</div>

<p>
不过这个封包还不能在物理网络上传输，因为它实际上只是 <b>vxlan tunnel上的packet</b>
</p>
</div>
</div>

<div id="outline-container-sec-3-2-4" class="outline-4">
<h4 id="sec-3-2-4">kernel的vxlan封包</h4>
<div class="outline-text-4" id="text-3-2-4">
<p>
将上述的packet从master node传输到minion node，需要将上述packet再次封包。这个任务在backend为vxlan的flannel network中由 <span class="underline">linux kernel</span> 来完成
</p>

<p>
flannel.1为vxlan设备，linux kernel可以自动识别，并将上面的packet进行 <b>vxlan封包</b> 处理。在这个封包过程中，kernel需要知道该数据包究竟发到哪个node上去。kernel需要查看当前节点上的 <b>fdb</b> ( <span class="underline">forwarding database</span> )以获得上面对端vtep设备（已经从arp table中查到其mac地址：d6:51:2e:80:5c:69）所在的节点地址。如果fdb中没有这个信息，那么kernel会向用户空间的flanned程序发起 <span class="underline">L2 MISS</span> 事件。flanneld收到该事件后，会查询etcd，获取该vtep设备对应的node的 <span class="underline">Public IP</span> ，并将信息注册到fdb中
</p>

<p>
这样Kernel就可以顺利查询到该信息并封包了：
</p>

<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node:</span>

$ bridge fdb show dev flannel.1 | grep d6:51:2e:80:5c:69
d6:51:2e:80:5c:69 dst {minion node local ip} self permanent
</pre>
</div>

<p>
由于目标ip是minion node，查找路由表，包应该从master node的 <b>eth0</b> 发出，这样 <span class="underline">src ip</span> 和 <span class="underline">src mac</span> 地址也就确定了。封好的包示意图如下：
</p>


<div class="figure">
<p><img src="pic/flannel-network-eth0-packet.png" alt="flannel-network-eth0-packet.png" width="70%" />
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3-2-5" class="outline-4">
<h4 id="sec-3-2-5">kernel的vxlan拆包</h4>
<div class="outline-text-4" id="text-3-2-5">
<p>
minion node上的eth0接收到上述vxlan包：
</p>
<ol class="org-ol">
<li>kernel将识别出这是一个vxlan包
</li>
<li>拆包后将flannel.1 packet转给minion node上的vtep（flannel.1）
</li>
<li>minion node上的flannel.1再将这个数据包转到minion node上的docker0
</li>
<li>docker0传输到Pod3的某个容器里
</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-sec-3-3" class="outline-3">
<h3 id="sec-3-3">Pod内到外部网络</h3>
<div class="outline-text-3" id="text-3-3">
<p>
pod中除了可以与pod network中的其他pod通信外，还可以访问外部网络，比如：
</p>
<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">master node:</span>
$ docker exec ba75f81455c7 ping -c 3 baidu.com

PING baidu.com (180.149.132.47): 56 data bytes
64 bytes from 180.149.132.47: <span style="color: #eedd82;">icmp_seq</span>=0 <span style="color: #eedd82;">ttl</span>=54 <span style="color: #eedd82;">time</span>=3.586 ms
64 bytes from 180.149.132.47: <span style="color: #eedd82;">icmp_seq</span>=1 <span style="color: #eedd82;">ttl</span>=54 <span style="color: #eedd82;">time</span>=3.752 ms
64 bytes from 180.149.132.47: <span style="color: #eedd82;">icmp_seq</span>=2 <span style="color: #eedd82;">ttl</span>=54 <span style="color: #eedd82;">time</span>=3.722 ms
--- baidu.com ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max/stddev = 3.586/3.687/3.752/0.072 m
</pre>
</div>

<p>
这个通信与vxlan就没有什么关系了，主要是通过docker引擎在 <span class="underline">iptables</span> 的 <span class="underline">POSTROUTING chain</span> 中设置的 <b>MASQUERADE</b> 规则
</p>

<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff4500;">#</span><span style="color: #ff4500;">mastre node:</span>

$ iptables -t nat -nL

... ...
Chain POSTROUTING (policy ACCEPT)
target     prot opt source               destination
MASQUERADE  all  --  172.16.99.0/24       0.0.0.0/0
</pre>
</div>

<p>
docker <b>将容器的pod network地址伪装为node ip出去，包回来时再snat回容器的pod network地址</b> ，这样网络就通了
</p>
</div>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="underline">不真实</span> 的Service网络</h2>
<div class="outline-text-2" id="text-4">
<p>
每当在k8s集群中创建一个service，k8s集群就会在 <span class="underline">-service-cluster-ip-range</span> 的范围内为service分配一个cluster-ip，只是一个 <b>虚拟的ip</b> ，并不真实绑定某个物理网络设备或虚拟网络设备，仅仅存在于 <span class="underline">iptables</span> 的规则中：
</p>
<div class="org-src-container">

<pre class="src src-sh">$ iptables -t nat -nL|grep 192.168.3

Chain KUBE-SERVICES (2 references)
target                     prot opt source               destination
KUBE-SVC-XGLOHA7QRQ3V22RZ  tcp  --  0.0.0.0/0            192.168.3.182        /* kube-system/kubernetes-dashboard: cluster IP */ tcp dpt:80
KUBE-SVC-NPX46M4PTMTKRN6Y  tcp  --  0.0.0.0/0            192.168.3.1          /* default/kubernetes:https cluster IP */ tcp dpt:443
KUBE-SVC-AU252PRZZQGOERSG  tcp  --  0.0.0.0/0            192.168.3.22         /* default/rbd-rest-api: cluster IP */ tcp dpt:8080
KUBE-SVC-TCOU7JCQXEZGVUNU  udp  --  0.0.0.0/0            192.168.3.10         /* kube-system/kube-dns:dns cluster IP */ udp dpt:53
KUBE-SVC-BEPXDJBUHFCSYIC3  tcp  --  0.0.0.0/0            192.168.3.179        /* default/my-nginx: cluster IP */ tcp dpt:80
KUBE-SVC-UQG6736T32JE3S7H  tcp  --  0.0.0.0/0            192.168.3.196        /* default/nginx-kit: cluster IP */ tcp dpt:80
KUBE-SVC-ERIFXISQEP7F7OF4  tcp  --  0.0.0.0/0            192.168.3.10         /* kube-system/kube-dns:dns-tcp cluster IP */ tcp dpt:53
</pre>
</div>

<p>
可以看到在PREROUTING环节，k8s设置了一个 <span class="underline">target: KUBE-SERVICES</span> 。而KUBE-SERVICES下面又设置了许多target，一旦 <span class="underline">destination</span> 和 <span class="underline">dstport</span> 匹配，就会沿着chain进行处理
</p>

<p>
比如：在pod网络 <span class="underline">curl 192.168.3.22 8080</span> 时，匹配到下面的 <b>KUBE-SVC-AU252PRZZQGOERSG target</b> ： 
</p>

<pre class="example">
KUBE-SVC-AU252PRZZQGOERSG  tcp  --  0.0.0.0/0            192.168.3.22         /* default/rbd-rest-api: cluster IP */ tcp dpt:8080
</pre>

<p>
沿着target，看到 <span class="underline">KUBE-SVC-AU252PRZZQGOERSG</span> 对应的内容如下：
</p>
<pre class="example">
Chain KUBE-SVC-AU252PRZZQGOERSG (1 references)
target                     prot opt source               destination
KUBE-SEP-I6L4LR53UYF7FORX  all  --  0.0.0.0/0            0.0.0.0/0            /* default/rbd-rest-api: */ statistic mode random probability 0.50000000000
KUBE-SEP-LBWOKUH4CUTN7XKH  all  --  0.0.0.0/0            0.0.0.0/0            /* default/rbd-rest-api: */

Chain KUBE-SEP-I6L4LR53UYF7FORX (1 references)
target          prot opt source               destination
KUBE-MARK-MASQ  all  --  172.16.99.6          0.0.0.0/0            /* default/rbd-rest-api: */
DNAT            tcp  --  0.0.0.0/0            0.0.0.0/0            /* default/rbd-rest-api: */ tcp to:172.16.99.6:8080

Chain KUBE-SEP-LBWOKUH4CUTN7XKH (1 references)
target          prot opt source               destination
KUBE-MARK-MASQ  all  --  172.16.99.7          0.0.0.0/0            /* default/rbd-rest-api: */
DNAT            tcp  --  0.0.0.0/0            0.0.0.0/0            /* default/rbd-rest-api: */ tcp to:172.16.99.7:8080
</pre>
<p>
请求被按5：5开的比例分发（起到负载均衡的作用）到 <span class="underline">KUBE-SEP-I6L4LR53UYF7FORX</span> 和 <span class="underline">KUBE-SEP-LBWOKUH4CUTN7XKH</span> ，而这两个chain的处理方式都是一样的，那就是先做mark，然后做 <span class="underline">dnat</span> ，将service ip改为pod network中的pod IP，进而请求被实际传输到某个service下面的pod中处理了
</p>
</div>
</div>
</div>
<div id="postamble" class="status">

		  <br/>
		  <div class='ds-thread'></div>
		  <script>
		  var duoshuoQuery = {short_name:'klose911'};
		  (function() {
					  var dsThread = document.getElementsByClassName('ds-thread')[0];
					  dsThread.setAttribute('data-thread-key', document.title);
					  dsThread.setAttribute('data-title', document.title);
					  dsThread.setAttribute('data-url', window.location.href);
					  var ds = document.createElement('script');
					  ds.type = 'text/javascript';ds.async = true;
					  ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
					  ds.charset = 'UTF-8';
					  (document.getElementsByTagName('head')[0] 
						|| document.getElementsByTagName('body')[0]).appendChild(ds);
					  })();
		  </script>
		  <script>
		  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
		  ga('create', 'UA-90850421-1', 'auto');
		  ga('send', 'pageview');
		  </script>
</div>
</body>
</html>
